{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "# This notebook is for course four : Classification Analysis (Supervised Learning)"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Importing Data Files"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#As part of the business objectives that you have set for Retailer X, \n#you must assist the retailer with understanding the factors that are \n#associated with the loyalty program participation to help them predict \n#in the future who is likely to participate or not. From this point, \n#Retailer X can direct the appropriate message to each customer effectively.\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Import Product DataSet here\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_4c73b4e9125d48cf93a58e32e4df6b8a = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='OrWgd56afrWso8TP28McZnZhIVT6iLoOUxmlRw_0RAgN',\n    ibm_auth_endpoint=\"https://iam.eu-gb.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_4c73b4e9125d48cf93a58e32e4df6b8a.get_object(Bucket='datascienceproject-donotdelete-pr-knsi3l5zevhael',Key='Product Data Set - Student 2 of 3.csv')['Body']\n",
            "execution_count": 65,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 65,
                    "data": {
                        "text/plain": "   PRODUCT CODE PRODUCT CATEGORY UNIT LIST PRICE\n0         30001  HEALTH & BEAUTY          $7.45 \n1         30002  HEALTH & BEAUTY          $5.35 \n2         30003  HEALTH & BEAUTY          $5.49 \n3         30004  HEALTH & BEAUTY          $6.46 \n4         30005  HEALTH & BEAUTY          $7.33 ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT CODE</th>\n      <th>PRODUCT CATEGORY</th>\n      <th>UNIT LIST PRICE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30001</td>\n      <td>HEALTH &amp; BEAUTY</td>\n      <td>$7.45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30002</td>\n      <td>HEALTH &amp; BEAUTY</td>\n      <td>$5.35</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30003</td>\n      <td>HEALTH &amp; BEAUTY</td>\n      <td>$5.49</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30004</td>\n      <td>HEALTH &amp; BEAUTY</td>\n      <td>$6.46</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30005</td>\n      <td>HEALTH &amp; BEAUTY</td>\n      <td>$7.33</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "#Import Transaction DataSet Here\nbody = client_4c73b4e9125d48cf93a58e32e4df6b8a.get_object(Bucket='datascienceproject-donotdelete-pr-knsi3l5zevhael',Key='Transaction Data Set - Student 3 of 3.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ntransaction_data = pd.read_csv(body,sep='|')\ntransaction_data.head()\n",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 10,
                    "data": {
                        "text/plain": "   CUSTOMER NUM  PRODUCT NUM  QUANTITY PURCHASED  DISCOUNT TAKEN  \\\n0         10114        30011                   4             0.0   \n1         10217        30016                   3             0.0   \n2         10224        30013                   4             0.0   \n3         10103        30012                   3             0.2   \n4         10037        30010                   8             0.0   \n\n  TRANSACTION DATE  STOCKOUT  \n0         1/2/2015         0  \n1         1/2/2015         0  \n2         1/2/2015         0  \n3         1/2/2015         0  \n4         1/2/2015         0  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CUSTOMER NUM</th>\n      <th>PRODUCT NUM</th>\n      <th>QUANTITY PURCHASED</th>\n      <th>DISCOUNT TAKEN</th>\n      <th>TRANSACTION DATE</th>\n      <th>STOCKOUT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10114</td>\n      <td>30011</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1/2/2015</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10217</td>\n      <td>30016</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1/2/2015</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10224</td>\n      <td>30013</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1/2/2015</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10103</td>\n      <td>30012</td>\n      <td>3</td>\n      <td>0.2</td>\n      <td>1/2/2015</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10037</td>\n      <td>30010</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>1/2/2015</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Import Customer Dataset Here\nbody = client_4c73b4e9125d48cf93a58e32e4df6b8a.get_object(Bucket='datascienceproject-donotdelete-pr-knsi3l5zevhael',Key='Customer Data Set - Student 1 of 3.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ncustomer_data=pd.read_csv(body)\ncustomer_data.head()\n",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 11,
                    "data": {
                        "text/plain": "   CUSTOMERID  GENDER  AGE    INCOME  EXPERIENCE SCORE LOYALTY GROUP  \\\n0       10001       0   64  $133,498                 5      enrolled   \n1       10002       0   42   $94,475                 9   notenrolled   \n2       10003       0   40   $88,610                 9      enrolled   \n3       10004       0   38   $84,313                 8      enrolled   \n4       10005       0   30   $51,498                 3   notenrolled   \n\n  ENROLLMENT DATE  HOUSEHOLD SIZE MARITAL STATUS  \n0      06-03-2013               4         Single  \n1             NaN               6        Married  \n2      02-09-2010               5        Married  \n3      06-04-2015               1         Single  \n4             NaN               1         Single  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CUSTOMERID</th>\n      <th>GENDER</th>\n      <th>AGE</th>\n      <th>INCOME</th>\n      <th>EXPERIENCE SCORE</th>\n      <th>LOYALTY GROUP</th>\n      <th>ENROLLMENT DATE</th>\n      <th>HOUSEHOLD SIZE</th>\n      <th>MARITAL STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10001</td>\n      <td>0</td>\n      <td>64</td>\n      <td>$133,498</td>\n      <td>5</td>\n      <td>enrolled</td>\n      <td>06-03-2013</td>\n      <td>4</td>\n      <td>Single</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10002</td>\n      <td>0</td>\n      <td>42</td>\n      <td>$94,475</td>\n      <td>9</td>\n      <td>notenrolled</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>Married</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10003</td>\n      <td>0</td>\n      <td>40</td>\n      <td>$88,610</td>\n      <td>9</td>\n      <td>enrolled</td>\n      <td>02-09-2010</td>\n      <td>5</td>\n      <td>Married</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10004</td>\n      <td>0</td>\n      <td>38</td>\n      <td>$84,313</td>\n      <td>8</td>\n      <td>enrolled</td>\n      <td>06-04-2015</td>\n      <td>1</td>\n      <td>Single</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10005</td>\n      <td>0</td>\n      <td>30</td>\n      <td>$51,498</td>\n      <td>3</td>\n      <td>notenrolled</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Single</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Changing Data Types"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "customer_data['INCOME']=customer_data['INCOME'].map(lambda x : x.replace('$',''))",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "customer_data['INCOME']=customer_data['INCOME'].map(lambda x : int(x.replace(',','')))",
            "execution_count": 13,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Creating Customer View"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "trans_products=transaction_data.merge(product_data,how='inner', left_on='PRODUCT NUM', right_on='PRODUCT CODE')",
            "execution_count": 15,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "trans_products['UNIT LIST PRICE']=trans_products['UNIT LIST PRICE'].map(lambda x : float(x.replace('$','')))",
            "execution_count": 16,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "trans_products['Total_Price']=trans_products['QUANTITY PURCHASED'] * trans_products['UNIT LIST PRICE'] * (1- trans_products['DISCOUNT TAKEN'])",
            "execution_count": 17,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "customer_prod_categ=trans_products.groupby(['CUSTOMER NUM','PRODUCT CATEGORY']).agg({'Total_Price':'sum'})",
            "execution_count": 18,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "customer_prod_categ=customer_prod_categ.reset_index()",
            "execution_count": 19,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "customer_pivot=customer_prod_categ.pivot(index='CUSTOMER NUM',columns='PRODUCT CATEGORY',values='Total_Price')",
            "execution_count": 20,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "trans_total_spend=trans_products.groupby('CUSTOMER NUM').agg({'Total_Price':'sum'}).\\\nrename(columns={'Total_Price':'TOTAL SPENT'})",
            "execution_count": 21,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "customer_KPIs=customer_pivot.merge(trans_total_spend,how='inner',left_index=True, right_index=True )",
            "execution_count": 22,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "customer_KPIs=customer_KPIs.fillna(0)\n",
            "execution_count": 23,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "customer_all_view=customer_data.merge(customer_KPIs,how='inner', left_on='CUSTOMERID', right_index=True)",
            "execution_count": 24,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "customer_all_view.head()",
            "execution_count": 25,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 25,
                    "data": {
                        "text/plain": "   CUSTOMERID  GENDER  AGE  INCOME  EXPERIENCE SCORE LOYALTY GROUP  \\\n0       10001       0   64  133498                 5      enrolled   \n1       10002       0   42   94475                 9   notenrolled   \n2       10003       0   40   88610                 9      enrolled   \n3       10004       0   38   84313                 8      enrolled   \n4       10005       0   30   51498                 3   notenrolled   \n\n  ENROLLMENT DATE  HOUSEHOLD SIZE MARITAL STATUS   APPAREL  ELECTRONICS  \\\n0      06-03-2013               4         Single  4022.430     1601.315   \n1             NaN               6        Married  2312.509     2473.163   \n2      02-09-2010               5        Married  2887.382     5414.418   \n3      06-04-2015               1         Single  3637.213     1840.211   \n4             NaN               1         Single   213.512        0.000   \n\n      FOOD  HEALTH & BEAUTY  TOTAL SPENT  \n0   68.688         1134.337     6826.770  \n1  276.779            0.000     5062.451  \n2  260.640            0.000     8562.440  \n3   45.270            0.000     5522.694  \n4    0.000            0.000      213.512  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CUSTOMERID</th>\n      <th>GENDER</th>\n      <th>AGE</th>\n      <th>INCOME</th>\n      <th>EXPERIENCE SCORE</th>\n      <th>LOYALTY GROUP</th>\n      <th>ENROLLMENT DATE</th>\n      <th>HOUSEHOLD SIZE</th>\n      <th>MARITAL STATUS</th>\n      <th>APPAREL</th>\n      <th>ELECTRONICS</th>\n      <th>FOOD</th>\n      <th>HEALTH &amp; BEAUTY</th>\n      <th>TOTAL SPENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10001</td>\n      <td>0</td>\n      <td>64</td>\n      <td>133498</td>\n      <td>5</td>\n      <td>enrolled</td>\n      <td>06-03-2013</td>\n      <td>4</td>\n      <td>Single</td>\n      <td>4022.430</td>\n      <td>1601.315</td>\n      <td>68.688</td>\n      <td>1134.337</td>\n      <td>6826.770</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10002</td>\n      <td>0</td>\n      <td>42</td>\n      <td>94475</td>\n      <td>9</td>\n      <td>notenrolled</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>Married</td>\n      <td>2312.509</td>\n      <td>2473.163</td>\n      <td>276.779</td>\n      <td>0.000</td>\n      <td>5062.451</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10003</td>\n      <td>0</td>\n      <td>40</td>\n      <td>88610</td>\n      <td>9</td>\n      <td>enrolled</td>\n      <td>02-09-2010</td>\n      <td>5</td>\n      <td>Married</td>\n      <td>2887.382</td>\n      <td>5414.418</td>\n      <td>260.640</td>\n      <td>0.000</td>\n      <td>8562.440</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10004</td>\n      <td>0</td>\n      <td>38</td>\n      <td>84313</td>\n      <td>8</td>\n      <td>enrolled</td>\n      <td>06-04-2015</td>\n      <td>1</td>\n      <td>Single</td>\n      <td>3637.213</td>\n      <td>1840.211</td>\n      <td>45.270</td>\n      <td>0.000</td>\n      <td>5522.694</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10005</td>\n      <td>0</td>\n      <td>30</td>\n      <td>51498</td>\n      <td>3</td>\n      <td>notenrolled</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Single</td>\n      <td>213.512</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>213.512</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Classification \nThe exploratory data analysis that you conducted in Course 2, \u201cData Understanding and Preparation\u201d showed that the most important features regarding LOYALTY GROUP participation are EXPERIENCE SCORE, TOTAL SPENT, INCOME, and AGE.\n\nSo, you use these features to create some classification models. However, you try different models and varied combination of features and contrast their performance."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Begin Writing your code here",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Create a Pandas data frame containing the most relevant features and the target \n#variable by using the following code:\n\nDF_classification=customer_all_view[['INCOME','AGE','EXPERIENCE SCORE','TOTAL SPENT','LOYALTY GROUP']]\nDF_classification.head(5)\n\n#Because \u201cLoyalty Group\u201d is a categorical label, we perform classification",
            "execution_count": 26,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 26,
                    "data": {
                        "text/plain": "   INCOME  AGE  EXPERIENCE SCORE  TOTAL SPENT LOYALTY GROUP\n0  133498   64                 5     6826.770      enrolled\n1   94475   42                 9     5062.451   notenrolled\n2   88610   40                 9     8562.440      enrolled\n3   84313   38                 8     5522.694      enrolled\n4   51498   30                 3      213.512   notenrolled",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INCOME</th>\n      <th>AGE</th>\n      <th>EXPERIENCE SCORE</th>\n      <th>TOTAL SPENT</th>\n      <th>LOYALTY GROUP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>133498</td>\n      <td>64</td>\n      <td>5</td>\n      <td>6826.770</td>\n      <td>enrolled</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94475</td>\n      <td>42</td>\n      <td>9</td>\n      <td>5062.451</td>\n      <td>notenrolled</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>88610</td>\n      <td>40</td>\n      <td>9</td>\n      <td>8562.440</td>\n      <td>enrolled</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84313</td>\n      <td>38</td>\n      <td>8</td>\n      <td>5522.694</td>\n      <td>enrolled</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>51498</td>\n      <td>30</td>\n      <td>3</td>\n      <td>213.512</td>\n      <td>notenrolled</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Separate the target from the numerical input features (predictors) and \n#create a Pandas data frame to hold only the target labels by using the following code:\n\ntarget_feature = pd.DataFrame(DF_classification['LOYALTY GROUP'])\nprint(type(target_feature))\ntarget_feature.head(5)",
            "execution_count": 27,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "<class 'pandas.core.frame.DataFrame'>\n",
                    "name": "stdout"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 27,
                    "data": {
                        "text/plain": "  LOYALTY GROUP\n0      enrolled\n1   notenrolled\n2      enrolled\n3      enrolled\n4   notenrolled",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LOYALTY GROUP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>enrolled</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>notenrolled</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>enrolled</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>enrolled</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>notenrolled</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Drop the categorical target from the \u201cDF_classification\u201d Pandas data frame \n#because you are scaling the columns of this data frame and you will later \n#merge the target with the scaled Pandas data frame. Use the following code:\n\nDF_classification = DF_classification.drop(['LOYALTY GROUP'],axis=1)\nDF_classification.head(5)\n#The Pandas data frame is ready for scaling.",
            "execution_count": 28,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 28,
                    "data": {
                        "text/plain": "   INCOME  AGE  EXPERIENCE SCORE  TOTAL SPENT\n0  133498   64                 5     6826.770\n1   94475   42                 9     5062.451\n2   88610   40                 9     8562.440\n3   84313   38                 8     5522.694\n4   51498   30                 3      213.512",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INCOME</th>\n      <th>AGE</th>\n      <th>EXPERIENCE SCORE</th>\n      <th>TOTAL SPENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>133498</td>\n      <td>64</td>\n      <td>5</td>\n      <td>6826.770</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94475</td>\n      <td>42</td>\n      <td>9</td>\n      <td>5062.451</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>88610</td>\n      <td>40</td>\n      <td>9</td>\n      <td>8562.440</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84313</td>\n      <td>38</td>\n      <td>8</td>\n      <td>5522.694</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>51498</td>\n      <td>30</td>\n      <td>3</td>\n      <td>213.512</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Scaling adjustment. You are using the Min-Max scaling approach, \n#which is shown in the following equation:Xsc = X - Xmin/Xmax - Xmin\n#Import the pre-processing library by using the following code:\nfrom sklearn import preprocessing",
            "execution_count": 29,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Save the column names of the input Pandas data frame in a \n#list before scaling by using the following code:\nDF_classification_column_names = DF_classification.columns.values\n#You save the columns names because when you apply the preprocessing command to \n#a Pandas data frame, the output is a NumPy array and the column names are lost.\n#To reconstruct the same data frame after scaling, you need the column names.",
            "execution_count": 30,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Add the following line to adjust the scales of the input features by using the following code:\n\nDF_classification=preprocessing.minmax_scale(DF_classification)",
            "execution_count": 31,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64.\n  app.launch_new_instance()\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Reconstruct the input Pandas data frame from the NumPy array by using the following code:\n\nDF_classification=pd.DataFrame(DF_classification, columns=DF_classification_column_names)\nDF_classification.head(5)\n#The output shows that the four features were scaled to the 0 - 1 range.",
            "execution_count": 32,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 32,
                    "data": {
                        "text/plain": "     INCOME       AGE  EXPERIENCE SCORE  TOTAL SPENT\n0  0.872818  0.638889          0.444444     0.446532\n1  0.572046  0.333333          0.888889     0.330790\n2  0.526842  0.305556          0.888889     0.560394\n3  0.493722  0.277778          0.777778     0.360983\n4  0.240799  0.166667          0.222222     0.012694",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INCOME</th>\n      <th>AGE</th>\n      <th>EXPERIENCE SCORE</th>\n      <th>TOTAL SPENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.872818</td>\n      <td>0.638889</td>\n      <td>0.444444</td>\n      <td>0.446532</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.572046</td>\n      <td>0.333333</td>\n      <td>0.888889</td>\n      <td>0.330790</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.526842</td>\n      <td>0.305556</td>\n      <td>0.888889</td>\n      <td>0.560394</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.493722</td>\n      <td>0.277778</td>\n      <td>0.777778</td>\n      <td>0.360983</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.240799</td>\n      <td>0.166667</td>\n      <td>0.222222</td>\n      <td>0.012694</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Concatenate the DF_classification with the target_feature data frame by using the following code:\n\nDF_classification = pd.concat([DF_classification,target_feature], axis=1)\nDF_classification.head(5)",
            "execution_count": 33,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 33,
                    "data": {
                        "text/plain": "     INCOME       AGE  EXPERIENCE SCORE  TOTAL SPENT LOYALTY GROUP\n0  0.872818  0.638889          0.444444     0.446532      enrolled\n1  0.572046  0.333333          0.888889     0.330790   notenrolled\n2  0.526842  0.305556          0.888889     0.560394      enrolled\n3  0.493722  0.277778          0.777778     0.360983      enrolled\n4  0.240799  0.166667          0.222222     0.012694   notenrolled",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INCOME</th>\n      <th>AGE</th>\n      <th>EXPERIENCE SCORE</th>\n      <th>TOTAL SPENT</th>\n      <th>LOYALTY GROUP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.872818</td>\n      <td>0.638889</td>\n      <td>0.444444</td>\n      <td>0.446532</td>\n      <td>enrolled</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.572046</td>\n      <td>0.333333</td>\n      <td>0.888889</td>\n      <td>0.330790</td>\n      <td>notenrolled</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.526842</td>\n      <td>0.305556</td>\n      <td>0.888889</td>\n      <td>0.560394</td>\n      <td>enrolled</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.493722</td>\n      <td>0.277778</td>\n      <td>0.777778</td>\n      <td>0.360983</td>\n      <td>enrolled</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.240799</td>\n      <td>0.166667</td>\n      <td>0.222222</td>\n      <td>0.012694</td>\n      <td>notenrolled</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Partitioning input data into training and testing splits\n#Import the train_test_split library by using the following code:\nfrom sklearn.model_selection import train_test_split",
            "execution_count": 34,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Run the following code to generate the training and testing data sets:\nX_train,X_test,Y_train,Y_test = \\\ntrain_test_split(DF_classification[['EXPERIENCE SCORE','TOTAL SPENT','INCOME']],DF_classification['LOYALTY GROUP'], test_size=0.2,random_state=42)\n\n#This code divides the input feature data frame by (80% - 20%) into two mutually exclusive Pandas data \n#frames (X_train(80%) for training and X_test(20%) for testing). It also separates the target feature \n#(class label) of both data sets into two separate data frames (Y_train for training and Y_test is for testing)\n#The random_state parameter is a pseudo-random number generator state that is used for random sampling when \n#splitting the input data into training and testing splits. If this number is set, then each time you run this \n#code, you get the same training and testing data splits. If the number is not specified, then you get different \n#data sets each time. In this example, we chose to set it so that when the code is run, you get the same results \n#as those in the document.\n",
            "execution_count": 35,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#age is removed from the training dataset since it has a higher correlation to income\n#Verify the relationship between both variables by using the following code:\nimport matplotlib.pyplot as plt \nplt.scatter(customer_all_view['AGE'],customer_all_view['INCOME'])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Income\")\nplt.show()",
            "execution_count": 42,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x288 with 1 Axes>",
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X+U1fV95/HniwF1oJoRBRf5UQyhpkYbf8wRDD05rFZFmxXaaiONK03dcDbHNBoTG1jdNWnMNjl0NUnTuEsiDaYG/BE7EmtKqdGm6xHMIBBEQ0WxMIMRDGCNsALDe//4fgYvw2Xm3sv93ntn5vU455659/P9fL/3fWeGefP58f18FBGYmZnlaUi9AzAzs4HPycbMzHLnZGNmZrlzsjEzs9w52ZiZWe6cbMzMLHdONmZmljsnGzMzy52TjZmZ5W5ovQNoFKeeempMnDix3mGYmfUrq1evfiMiRvVVz8kmmThxIu3t7fUOw8ysX5H0b6XUczeamZnlzsnGzMxy52RjZma5c7IxM7PcOdmYmVnuPBvNzGwQur1tPUtWbaUrgiaJ2VPGc+esc3J7PycbM7NB5va29fztyi2HXndFHHqdV8JxsjEzGwTa1nSyYPlGtu3eSxylzpJVW51szMysMm1rOrn14XXs7zpamsl0Re/Hj4WTjZnZAFDYcjm9pZnhxw3hpe1v1zusQ5xszMz6ocLk0jJ8GLv27D90rHP33jpGVpyTjZlZP9OzW6ww0RyLsS3NVblOMb7Pxsysn/niDzf0Of5SruZhTdx6+ZlVvWYht2zMzPqZarVkJCDg9JZmbr38TGadN7Yq1y3GycbMrM56Du5PPKWZla/sOnTD5XtHDeeVHXsOva6GYUPEgms+mGuCKeRkY2ZWRz3HXzp37z1sgL8r4rBZZZVOT548egR79h08lNDybsn05GRjZlZjhS0ZCQ7mcHvLtEkjuf8TF1X/whVysjEzq6KeXWL/8f2jePLnOw57/YPVnezd3wVANe+jHNvSzNPzLq7eBavIycbMrEra1nRyy4NrD7VUOnfvPWwNss7de7l/5ZajLhdzLPKeTXasnGzMzMrQ22B+KaqVaKZNGsmrv9xbtzGYcuWWbCQtAj4CbI+Is3sc+xywABgVEW9IEvB14EpgD/DHEfFcqjsHuD2demdELE7lFwDfBZqBx4GbIiIkjQQeACYCrwJ/GBG78vqcZjZ4tK3p5LMPraPrYPHB/DwUm42W93YAecizZfNd4JvAfYWFksYDlwJbCoqvACanxxTgHmBKShx3AK1k/yFYLWlZSh73AHOBlWTJZgbwI2Ae8EREfEXSvPT68zl9RjMbQIrt8bJ5x694+uWdVX2fdHvLUdV6WnIt5JZsIuInkiYWOXQ38GfAowVlM4H7IiKAlZJaJI0BpgMrImIngKQVwAxJTwEnRcQzqfw+YBZZspmZzgNYDDyFk42ZcWQymfrekw91RQ0/rom393Udqlu4x0s1NQ9r4g8uGHvEpIHC143eJVaJmo7ZSLoK6IyIdTr8xqSxwNaC1x2prLfyjiLlAKdFxGsAEfGapNG9xDOXrHXEhAkTKvlIZtbACsdXmocNYc/+g4eOdUUc1mIpTDTVdvzQIew7cHDAJpJS1CzZSBoO3AZcVuxwkbKooLwsEbEQWAjQ2tqa30YOZla23lohxf5oF6v/7Ku7Dt0sWZhoaqnR7nepl1q2bCYBZwDdrZpxwHOSLiRrmYwvqDsO2JbKp/cofyqVjytSH+B1SWNSq2YMsL3qn8TMqq6wFVKsS6uwFdK5ey/zH1kPwKzzxhbd5rja4yy96R6D6a+D97VQs2QTEeuBQ11akl4FWtNstGXApyQtJZsg8GZKFsuB/ynp5HTaZcD8iNgp6S1JU4FVwPXAX6U6y4A5wFfS18KxITNrAMVaISs37zo0y6uULq29+7tYsHwjs84by5JVW/usnwcnl9LlOfV5CVmr5FRJHcAdEXHvUao/TjbteRPZ1OePA6Sk8iXgp6nen3dPFgA+ybtTn3+UHpAlmQcl3UA24+2aKn4sMztG1WyFbEvTjqu1nXHTEHHwYBzWSuk5G83dYpXJczba7D6OTyx4HsCNR6m3CFhUpLwdOLtI+S+BS8oM18xyVNhFVs3B0dPTZl9NUsUJ5+Thw9i9Z/+gHryvBa8gYGZVV5hc3tM8jLfeOXCoi6xaCpdnmT1lfEnTlIcA73FyqQsnGzMrS8/lWm69/Ez+4vEXeP2tfUXr795bnY2+AIYNgQMHj9zsq3vMpOcNma2/PvKIWJ1c6kNRzSVH+7HW1tZob2+vdxhmDa3nci215LGSxiRpdUS09lXPLRsz61VhSwaqt5BkT6edeBxv/Gp/v17/y47OycbMjqrnLpJ5catl4HOyMbPDHNaSUXU39+o2EBeatN452ZjZIUe0ZKqUaDwLzJxszAa5wpaMBJWM/Z/QJP5fQVfbScc3cWLzcZ4FZoc42ZgNYj1bMuV2mXkg30rlZGM2iPS8R2b3nn0VDf63NA9j7R3FFnA3K87JxmyQKLalcSWGDRFfuOoD1QzNBoEh9Q7AzGrjtr9bX9HNmEOUtWQEjG1p9iwyq4hbNmYD2LEsgCmOXBbGrFJONmYDVNuaTuY/sp69+8vf7thjMlZt7kYzG6AWLN9YUaLxmIzlwS0bswGkkm6zYUNg9EnNvifGcuVkYzZAVNJtNgRYcM25Ti6WOycbs36ssCUzpIzdKj34b7XmZGPWT/W8b6bURDO2pZmn512cZ2hmR3CyMetHLr3rKV7a/nbF5xdupWxWS042Zg3qY99+hqdf3nnodc/FLsvhbjOrt9ySjaRFwEeA7RFxdipbAPwnYB/wMvDxiNidjs0HbgC6gE9HxPJUPgP4OtAEfCcivpLKzwCWAiOB54D/HBH7JB0P3AdcAPwS+GhEvJrX5zSrltvb1rNk1dajdodVmmgANn/ldys+16wa8rzP5rvAjB5lK4CzI+K3gH8F5gNIOgu4FvhAOudbkpokNQF/DVwBnAXMTnUBvgrcHRGTgV1kiYr0dVdEvA+4O9Uza2i3t63nb1duKXncpRzTJo2s+jXNypVbyyYifiJpYo+yfyx4uRK4Oj2fCSyNiHeAzZI2ARemY5si4hUASUuBmZJeBC4G/ijVWQx8AbgnXesLqfxh4JuSFJHHfoNmlTuWpWRK5e2WrVHUc8zmT4AH0vOxZMmnW0cqA9jao3wKcAqwOyIOFKk/tvuciDgg6c1U/41qfwCzo+m5lP+tl5/JQ+1bDhuDyct1Uyd4fxlrOHVJNpJuAw4A93cXFakWFO/mi17q93atYnHMBeYCTJgwoZeIzXo35csreP2tfUWPde7ey80PrM3lfU86vom39x2kK8IbmVlDq3mykTSHbOLAJQVdWx3A+IJq44Bt6Xmx8jeAFklDU+umsH73tTokDQXeAxT972RELAQWArS2trqbzSrSW6KptsmjR7Diluk1eS+zaqrpQpxpZtnngasiYk/BoWXAtZKOT7PMJgPPAj8FJks6Q9JxZJMIlqUk9STvjvnMAR4tuNac9Pxq4Mcer7E8OdGY9S3Pqc9LgOnAqZI6gDvIZp8dD6yQBLAyIv5rRGyQ9CDwAln32o0R0ZWu8ylgOdnU50URsSG9xeeBpZLuBNYA96bye4HvpUkGO8kSlFm/5PEXGyjk//RnWltbo729vd5hWD/R84bLavP4i/UXklZHRGtf9byCgFmZKkk0w4aIiacO73WpmROaxM+/fOWxhmfWkJxszMpUTqLxMjFmGScbsxIU3jdTDi8TY5ZxsjHrQ9uaTm55cC0HyxzebGkelk9AZv2Qk41ZEX0titmXYUPEF676QJWjMuu/nGzMeuheFLMSHqMxK87Jxga9ak1jbpJ4+S88m8ysmJquIGDWaKp5v8zsKeP7rmQ2SLllY4NatVo0vgHTrHdONmYV8l4xZqVzN5pZBZxozMrjlo1ZiZxgzCrnlo1ZCZxozI6NWzZmR/Gql5oxqxonGxt08t4ewMyO5G40G1ScaMzqw8nGBhUnGrP6cLIxK8IrNptVl5ONWQ9esdms+jxBwCzxis1m+XGyMUu8q6ZZfpxsbMA71o3QzOzY5TZmI2mRpO2Sni8oGylphaSX0teTU7kkfUPSJkk/k3R+wTlzUv2XJM0pKL9A0vp0zjckqbf3sMGpeyM0Jxqz+spzgsB3gRk9yuYBT0TEZOCJ9BrgCmByeswF7oEscQB3AFOAC4E7CpLHPalu93kz+ngPG4S+v6qyHTfNrLpySzYR8ROg500NM4HF6fliYFZB+X2RWQm0SBoDXA6siIidEbELWAHMSMdOiohnIiKA+3pcq9h72CB00A0as4ZQ66nPp0XEawDp6+hUPhbYWlCvI5X1Vt5RpLy39ziCpLmS2iW179ixo+IPZf3f5NEj6h2C2YDWKBMEVKQsKigvS0QsBBYCtLa2+v/AA0Tbmk4WLN/Itt17S6o/efQIVtwyPd+gzAa5Wieb1yWNiYjXUlfY9lTeARRu4D4O2JbKp/cofyqVjytSv7f3sEGgbU0nn31oHV0l9J95VWez2ql1N9oyoHtG2Rzg0YLy69OstKnAm6kLbDlwmaST08SAy4Dl6dhbkqamWWjX97hWsfewQeC2v1tfUqIxs9rKrWUjaQlZq+RUSR1ks8q+Ajwo6QZgC3BNqv44cCWwCdgDfBwgInZK+hLw01TvzyOie9LBJ8lmvDUDP0oPenkPGwTe3tdV7xDMrIjckk1EzD7KoUuK1A3gxqNcZxGwqEh5O3B2kfJfFnsPs0KeEGBWW40yQcCsIpXsT+MJAWa152Rj/Va5icYTAszqp6QJApJ+Q9IT3UvPSPotSbfnG5pZ77wRmln/UepstG8D84H9ABHxM+DavIIyM7OBpdRutOER8Wxa67LbgRziMetVuTdsdvPOm2b1VWqyeUPSJNJd+pKuBl7LLSqzItrWdPKZB9aWvVSEd940q79Sk82NZMu6vF9SJ7AZuC63qMyK+NxD60pONGNbmtm2e6933jRrECUlm4h4BfgdSSOAIRHxVr5hmR3pQBkrAzw97+IcIzGzcpWUbCS1kC0JMxEY2j12ExGfzi0yMzMbMErtRnscWAmsBw7mF47Z4SrZ0nnapJE5RmRmlSg12ZwQEbfkGolZD91bOpdj2qSR3P+Ji3KKyMwqVWqy+Z6kTwCPAe90FxYsimlWdfeXkWi8OoBZYys12ewDFgC38e4mZQG8N4+gzKCC3fDMrGGVmmxuAd4XEW/kGYxZJQtrmlnjK3W5mg1k+8yY5abSRPO1j56bQzRmVk2ltmy6gLWSnuTwMRtPfbaqKSfRCHzDplk/UmqyaUsPs4aw2RMCzPqVUlcQWCzpOOA3UtHGiNifX1g2WFRyH42Z9T+lriAwHVgMvErWgzFe0pyI+El+odlAV8l9NADXTZ2QQzRmlqdSu9H+F3BZRGyEbDM1YAlwQV6B2cBXbqJpkpg9ZTx3zjonp4jMLC+lJpth3YkGICL+VZI3CLGa8KoAZv1fqVOf2yXdK2l6enwbWF3pm0r6jKQNkp6XtETSCZLOkLRK0kuSHkhjREg6Pr3elI5PLLjO/FS+UdLlBeUzUtkmSfMqjdPqz4nGbGAotWXzSbI9bT5NNmbzE+BblbyhpLHpOmdFxF5JD5JtMX0lcHdELJX0v4EbgHvS110R8T5J1wJfBT4q6ax03geA04F/St17AH8NXAp0AD+VtCwiXqgkXquecu6j8fIzZgNLqS2bocDXI+L3I+L3gG8ATcfwvkOBZklDgeFku35eDDycji8GZqXnM9Nr0vFLlO1xMBNYGhHvRMRmYBNwYXpsiohXImIfsDTVtTryygBmg1upyeYJoLngdTPwT5W8YUR0An8JbCFLMm+SdcntjogDqVoH0H2n3lhgazr3QKp/SmF5j3OOVm515ERjNriVmmxOiIhfdb9Iz4dX8oaSTiZraZxB1v01AriiSNXuGy90lGPllheLZa6kdkntO3bs6Ct0MzOrUKnJ5m1J53e/kHQBsLfC9/wdYHNE7Eg3hj4CfAhoSd1qAOOAbel5BzA+ve9Q4D3AzsLyHuccrfwIEbEwIlojonXUqFEVfhyrNm9+ZjbwlDpB4GbgIUndf7THAB+t8D23AFMlDSdLWJcA7cCTwNVkYyxzgEdT/WXp9TPp+I8jIiQtA74v6S6yFtJk4Fmyls1kSWcAnWSTCP6owljtGFQyTuPZZ2YDU6nL1fxU0vuBM8n+mP+80uVqImKVpIeB54ADwBpgIfD3wFJJd6aye9Mp95Jt3raJrEVzbbrOhjST7YV0nRsjogtA0qeA5WSTGBZFxIZKYrXKeeaZmRVSlLgmlaQPARMpSFARcV8+YdVea2trtLe31zuMfq1tTScLlm9k2+69ZW185mRj1n9JWh0RrX3VK3VttO8Bk4C1ZNsNQDboPmCSjR2btjWd3PrwOvZ3eUFNMztSqWM2rWQ3YfoviRX1xR9uqCjRTB49IodozKzRlDob7XngP+QZiPVvu/aUP4Q3efQIVtwyvfrBmFnDKbVlcyrwgqRnOXynzqtyicoGNI/RmA0+pSabL+QZhA0evofGbHAqderzP+cdiA18vofGbPDqNdlIeoviS70IiIg4KZeobEBxt5mZ9ZpsIuLEWgViZmYDV6ljNmZHuPSup3hp+9v1DsPM+oFSpz6bHcaJxszK4WRjFXGiMbNyONmYmVnunGwsV8V2sjOzwcfJxnL1sakT6h2CmTUAz0azXDRJzJ4ynjtnnVPvUMysATjZWElub1vPklVb6YqgSb13jvkmTjPrycnG+nR723r+duWWQ6+7vNOEmZXJYzbWp++v2tJ3JTOzXjjZWJ8OuiFjZsfIycaqaph/o8ysCP9psKpacM259Q7BzBqQk40dk7EtzSh9/dpHz2XWeWPrHZKZNaC6zEaT1AJ8BzibbL+cPwE2Ag8AE4FXgT+MiF2SBHwduBLYA/xxRDyXrjMHuD1d9s6IWJzKLwC+CzQDjwM3RXgKVR6enndxvUMws36gXi2brwP/EBHvBz4IvAjMA56IiMnAE+k1wBXA5PSYC9wDIGkkcAcwBbgQuEPSyemce1Ld7vNm1OAzDSi3t61n0vzHmTjv7+sdipkNADVPNpJOAj4M3AsQEfsiYjcwE1icqi0GZqXnM4H7IrMSaJE0BrgcWBEROyNiF7ACmJGOnRQRz6TWzH0F17ISdN9X4/tpzKxa6tGyeS+wA/gbSWskfUfSCOC0iHgNIH0dneqPBbYWnN+Rynor7yhSfgRJcyW1S2rfsWPHsX+yAaLwBk4zs2qoR7IZCpwP3BMR5wFv826XWTHF1kaJCsqPLIxYGBGtEdE6atSo3qM2M7OK1WOCQAfQERGr0uuHyZLN65LGRMRrqStse0H98QXnjwO2pfLpPcqfSuXjitS3XrSt6WTB8o1s27235HOmTRqZY0RmNpDUvGUTEb8Atko6MxVdArwALAPmpLI5wKPp+TLgemWmAm+mbrblwGWSTk4TAy4Dlqdjb0mammayXV9wLSuibU0ntz68js7de4s3AYuYNmkk93/iolzjMrOBo14Lcf4pcL+k44BXgI+TJb4HJd0AbAGuSXUfJ5v2vIls6vPHASJip6QvAT9N9f48Inam55/k3anPP0oPO4ov/nAD+7tKSzNe0dnMKlGXZBMRa4HWIocuKVI3gBuPcp1FwKIi5e1k9/BYCXbt2V/vEMxsgPMKAlYyr3tmZpXynw8rmdc9M7NKefM065WA01uaufXyM73umZlVzMnGerXZEwLMrArcjWZmZrlzsjEzs9y5G22QuvSup3hp+9v1DsPMBgm3bAYhJxozqzUnm0HIicbMas3daIPA7W3rWbJqK10RNKnYotjFnXbicTlGZWaDiZPNANe9EVq3UjdEO+3E41h126V5hWVmg4yTzQBX7kZoXmjTzPLgMRszM8udk40dUs54jplZOdyNNgB97NvP8PTLO/uu2MPsKeP7rmRmVgG3bAaYchJNd0umSeK6qRO4c9Y5eYZmZoOYWzYDQNuaThYs38i2MrZ1Bnj5L67MLSYzs0JONv1c25pObn5gbb3DMDPrlbvR+rnPVJhopk0aWeVIzMyOzi2bfqjSbrNu0yaN5P5PXFT1uMzMjsbJpp9pW9PJLQ+u5WAFWcY3bJpZvdStG01Sk6Q1kh5Lr8+QtErSS5IekHRcKj8+vd6Ujk8suMb8VL5R0uUF5TNS2SZJ82r92fL0+R/8rKJE424zM6uneo7Z3AS8WPD6q8DdETEZ2AXckMpvAHZFxPuAu1M9JJ0FXAt8AJgBfCslsCbgr4ErgLOA2anugPDOgYNln+NuMzOrt7p0o0kaB/wu8GXgFkkCLgb+KFVZDHwBuAeYmZ4DPAx8M9WfCSyNiHeAzZI2ARemepsi4pX0XktT3Rdy/li5KRyjKYe7zcysUdSrZfM14M+A7v+mnwLsjogD6XUHMDY9HwtsBUjH30z1D5X3OOdo5f1S25pO5j+yns4yJwNMHj0it5jMzMpV82Qj6SPA9ohYXVhcpGr0cazc8mKxzJXULql9x44dvURdPwuWb2Tv/q6yzpk8egQrbpmeT0BmZhWoRzfaNOAqSVcCJwAnkbV0WiQNTa2XccC2VL8DGA90SBoKvAfYWVDerfCco5UfJiIWAgsBWltbK5lFnLvOMrrO3G1mZo2q5skmIuYD8wEkTQc+FxEfk/QQcDWwFJgDPJpOWZZeP5OO/zgiQtIy4PuS7gJOByYDz5K1bCZLOgPoJJtE0D0W1PAq3VXTzKyRNdJ9Np8Hlkq6E1gD3JvK7wW+lyYA7CRLHkTEBkkPkg38HwBujIguAEmfApYDTcCiiNhQ009SoUp31QRPbTazxqYo4w/aQNba2hrt7e11jeGMeX/vFQHMrF+RtDoiWvuq10gtm0HpWJae8RiNmfUXTjZ1dCxLz5iZ9Sde9bmOKl16BuC6qROqG4yZWY6cbOqonKVnvKummfVn7karsUqXnvGummbWnznZ1FD30jPlrgjgLjMz6++cbGqo3KVnmiRmTxnvLjMz6/ecbGrIS8+Y2WDlCQINaJh/KmY2wPjPWgNacM259Q7BzKyq3I2Ws1Jnnwk4vaWZWy8/k1nn9dvtd8zMinKyyVHbmk5ufXgd+7v6vnNzs8dozGwAczdajr74ww0lJRozs4HOySZHu/bsr3cIZmYNwcmmAXj2mZkNdP4z1wA8+8zMBjpPEKiicrZ09uwzMxtMnGyqpNwtnT37zMwGEyebY3Asu2yamQ0mTjYValvTyWceWOskY2ZWAk8QqNDnHlpXcaLx7DMzG2z8Z69CByrdzxnPPjOzwafmyUbSeElPSnpR0gZJN6XykZJWSHopfT05lUvSNyRtkvQzSecXXGtOqv+SpDkF5RdIWp/O+YbUx9SwnI1taUbp69c+eq5nn5nZoFOPMZsDwGcj4jlJJwKrJa0A/hh4IiK+ImkeMA/4PHAFMDk9pgD3AFMkjQTuAFqBSNdZFhG7Up25wErgcWAG8KMafsZDnFzMzOrQsomI1yLiufT8LeBFYCwwE1icqi0GZqXnM4H7IrMSaJE0BrgcWBERO1OCWQHMSMdOiohnIiKA+wquVRNuxZiZHa6us9EkTQTOA1YBp0XEa5AlJEmjU7WxwNaC0zpSWW/lHUXKi73/XLIWEBMmTDi2D1PA99CYmR2ubhMEJP0a8APg5oj4996qFimLCsqPLIxYGBGtEdE6atSovkLuM6jeys3MBrO6JBtJw8gSzf0R8Ugqfj11gZG+bk/lHcD4gtPHAdv6KB9XpLyqPja1eEvoaOVmZoNZPWajCbgXeDEi7io4tAzonlE2B3i0oPz6NCttKvBm6m5bDlwm6eQ0c+0yYHk69pakqem9ri+4VtXcOescrps64dAaaE0S102dwJ2zzqn2W5mZ9XuKPtbwqvobSr8N/AuwHjiYiv8b2bjNg8AEYAtwTUTsTAnjm2QzyvYAH4+I9nStP0nnAnw5Iv4mlbcC3wWayWah/Wn08UFbW1ujvb29Wh/TzGxQkLQ6Ilr7rFfrZNOonGzMzMpXarLxCgJmZpY7JxszM8udk42ZmeXOycbMzHLnCQKJpB3Av+X4FqcCb+R4/WpxnNXVX+KE/hOr46yuY43z1yOiz7vinWxqRFJ7KTM26s1xVld/iRP6T6yOs7pqFae70czMLHdONmZmljsnm9pZWO8ASuQ4q6u/xAn9J1bHWV01idNjNmZmlju3bMzMLHdONlUmabykJyW9KGmDpJtS+UhJKyS9lL6eXOc4T5D0rKR1Kc4vpvIzJK1KcT4g6bh6xtlNUpOkNZIeS68bNc5XJa2XtFZS94KxDfWzTzG1SHpY0s/T7+pFjRanpDPT97H78e+Sbm60OLtJ+kz6t/S8pCXp31jD/Z5KuinFuEHSzaks9++pk031HQA+GxG/CUwFbpR0FjAPeCIiJgNPpNf19A5wcUR8EDiXbEvtqcBXgbtTnLuAG+oYY6GbyLYQ79aocQL8x4g4t2A6aaP97AG+DvxDRLwf+CDZ97ah4oyIjen7eC5wAdmq739Hg8UJIGks8GmgNSLOBpqAa2mw31NJZwOfAC4k+7l/RNJkavE9jQg/cnyQ7aVzKbARGJPKxgAb6x1bQYzDgeeAKWQ3dw1N5ReR7RFU7/jGpX8AFwOPkW2I2nBxplheBU7tUdZQP3vgJGAzacy2UePsEdtlwNONGifvblM/Ehiafk8vb7TfU+Aa4DsFr/878Ge1+J66ZZMjSROB88j26jktso3dSF9H1y+yTOqaWku2K+oK4GVgd0QcSFU6yP4R1dvXyP5BdO9/dAqNGSdkW5D/o6TVkuamskb72b8X2AH8Teqa/I6kETRenIWuBZak5w0XZ0R0An9JthfXa8CbwGoa7/f0eeDDkk6RNBy4kmzH49y/p042OZH0a2RbX98cEf9e73iKiYiuyLooxpE1q3+zWLXaRnU4SR8BtkfE6sLiIlUbZVrltIg4H7iCrAv1w/UOqIihwPnAPRFxHvA2DdAVdTRpnOMq4KF6x3I0aYxjJnAGcDowgux3oKe6/p5GxItkXXsrgH8A1pF1/efOySbd2306AAADE0lEQVQHkoaRJZr7I+KRVPy6pDHp+Biy1kRDiIjdwFNkY0wtkoamQ+OAbfWKK5kGXCXpVWApWVfa12i8OAGIiG3p63ay8YULabyffQfQERGr0uuHyZJPo8XZ7QrguYh4Pb1uxDh/B9gcETsiYj/wCPAhGvD3NCLujYjzI+LDwE7gJWrwPXWyqTJJAu4FXoyIuwoOLQPmpOdzyMZy6kbSKEkt6Xkz2T+WF4EngatTtbrHGRHzI2JcREwk60r5cUR8jAaLE0DSCEkndj8nG2d4ngb72UfEL4Ctks5MRZcAL9BgcRaYzbtdaNCYcW4Bpkoanv4GdH9PG/H3dHT6OgH4fbLvbf7f03oPrA20B/DbZE3lnwFr0+NKsnGGJ8j+F/EEMLLOcf4WsCbF+TzwP1L5e4FngU1k3RbH1/t7WhDzdOCxRo0zxbQuPTYAt6XyhvrZp5jOBdrTz78NOLlB4xwO/BJ4T0FZw8WZ4voi8PP07+l7wPEN+nv6L2SJcB1wSa2+p15BwMzMcuduNDMzy52TjZmZ5c7JxszMcudkY2ZmuXOyMTOz3DnZmDUASb8nKSS9v96xmOXBycasMcwG/i/ZjatmA46TjVmdpXX0ppEtP39tKhsi6Vtpz5HHJD0u6ep07AJJ/5wW+1zevcyIWSNzsjGrv1lke8v8K7BT0vlky4hMBM4B/gvZ8vTd6+79FXB1RFwALAK+XI+gzcoxtO8qZpaz2WSLi0K22OhsYBjwUEQcBH4h6cl0/EzgbGBFtgQXTWRL2ps1NCcbszqSdArZStZnSwqy5BFkK0YXPQXYEBEX1ShEs6pwN5pZfV0N3BcRvx4REyNiPNkumm8Af5DGbk4jW4QUsh0VR0k61K0m6QP1CNysHE42ZvU1myNbMT8g24Crg2wF4f9DttvrmxGxjyxBfVXSOrJVxT9Uu3DNKuNVn80alKRfi4hfpa62Z8l2Af1FveMyq4THbMwa12Npg7vjgC850Vh/5paNmZnlzmM2ZmaWOycbMzPLnZONmZnlzsnGzMxy52RjZma5c7IxM7Pc/X9M5LWe8qGZewAAAABJRU5ErkJggg==\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Training a K-Nearest Neighbor Classifier\n#Complete the following steps:\nfrom sklearn.neighbors import KNeighborsClassifier\n#Create an instance of the KNN classifier by using the following code. As an initial setting, you use the eight \n#nearest neighbors to classify the output. Later, you drive the optimal k by using cross-validation.\nclf_kNN = KNeighborsClassifier(n_neighbors=8)",
            "execution_count": 43,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Observe the algorithm parameters by issuing the classifier instance name by using the following code:\n\nclf_kNN",
            "execution_count": 44,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 44,
                    "data": {
                        "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n           weights='uniform')"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#The n_neighbors = 8 value is what we specified. The rest of the parameters are assigned the default values and are explained as follows:\n#Algorithm: This is the method or the algorithm that is used to calculate the nearest neighbors. It is set to auto, which means that the KNN attempts to decide the most appropriate algorithm based on the values that are passed to the fit method. The fit method is explained soon.\n#Leaf size: This parameter specifies the number of points that are used to calculate the nearest neighbor points. It can significantly impact the speed of the calculations and the memory that is required.\n#Metric: The distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric.\n#Weights: The weight function that is used in prediction. Uniform weights mean that all points in each neighborhood are weighted equally.",
            "execution_count": 45,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Train the KNN classifier by using the fit function by using the following code:\n\nclf_kNN.fit(X_train, Y_train)\n\n#The function fit(X, y) trains the model by using X as the training data and y as the target values. It accepts input data as Pandas data frames.\n\ntype(X_train)",
            "execution_count": 46,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 46,
                    "data": {
                        "text/plain": "pandas.core.frame.DataFrame"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#To test the model, first use the model to predict the labels of the testing feature set by using the following code:\n\npredicted = clf_kNN.predict(X_test)\n\n#This line returns the predicted labels of the test data in a numpy array. Run a type command to verify.\n\ntype(predicted)",
            "execution_count": 47,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 47,
                    "data": {
                        "text/plain": "numpy.ndarray"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Compare the predicted values to the actual values of the testing target labels (Y_test) by performing the following steps:\n#Use scikit, which is a metrics library that evaluates the performance of the classifier\n#Import the library by using the following code:\nfrom sklearn import metrics",
            "execution_count": 48,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Testing\n#Compare the predicted values to the actual values of the testing target labels (Y_test) by performing the following steps:\n\nacc = metrics.accuracy_score(Y_test,predicted)\nprint ('accuracy = '+str(acc*100)+'%')\nprint (metrics.classification_report(Y_test,predicted))",
            "execution_count": 49,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "accuracy = 79.0%\n              precision    recall  f1-score   support\n\n    enrolled       0.73      0.92      0.82        51\n notenrolled       0.89      0.65      0.75        49\n\n   micro avg       0.79      0.79      0.79       100\n   macro avg       0.81      0.79      0.79       100\nweighted avg       0.81      0.79      0.79       100\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#The output shows the following information:\n#An overall accuracy of 79% means that the model was able to predict correctly the labels of 79% of the input testing data set.\n#Each class label (enrolled or not enrolled) is treated separately as follows: (Hint: Remember the confusion matrix.)\n#Enrolled:\n#It has a precision of 73%, which means that the whenever the model predicts or outputs \u201cenrolled\u201d, you can trust it by 73%.\n#It has a recall of 89%, which means that whenever the true label of an unknown input sample is \u201cenrolled\u201d, the model can predict it correctly by 89%.\n#It has an f1-score of 82%, which is a weighted sum of the precision and recall.\n#Not enrolled:\n#It has a precision of 89%, which means that the whenever the model predicts \u201cnot enrolled\u201d, you can trust it by 89%.\n#It has a recall of 65%, which means that whenever the true label of an unknown input sample is \u201cnot enrolled\u201d, the model can predict it correctly by 65%.\n#It has an f1-score of 75%, which is a weighted sum of the precision and recall.\n#Support is the actual number of class labels.",
            "execution_count": 50,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Training using the decision tree classifier\nfrom sklearn.tree import DecisionTreeClassifier\n",
            "execution_count": 55,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Create an instance of the algorithm with criterion = entropy by using the following code:\n#We set the criterion = \u201centropy\u201d. Entropy is the algorithm that the decision trees use to split nodes. \n#For more information about the other model parameters, clf = DecisionTreeClassifier(random_state=0)\n#see http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html.\n\nclf_Tree=DecisionTreeClassifier(criterion='entropy',random_state=0)",
            "execution_count": 57,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Observe the algorithm parameters by issuing the classifier instance name by using the following code:\nclf_Tree",
            "execution_count": 58,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 58,
                    "data": {
                        "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n            splitter='best')"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Like what you did with the KNN model, train and test the tree model by using the following code:\n\nclf_Tree.fit(X_train, Y_train)\npredicted = clf_Tree .predict(X_test)\nacc = metrics.accuracy_score(Y_test,predicted)\nprint ('accuracy = '+str(acc*100)+'%')\nprint (metrics.classification_report(Y_test,predicted))",
            "execution_count": 59,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "accuracy = 75.0%\n              precision    recall  f1-score   support\n\n    enrolled       0.74      0.78      0.76        51\n notenrolled       0.76      0.71      0.74        49\n\n   micro avg       0.75      0.75      0.75       100\n   macro avg       0.75      0.75      0.75       100\nweighted avg       0.75      0.75      0.75       100\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Decision trees have an advantage over KNN in that they provide numerical \n#values for the feature importance. You can use this feature to provide Retailer X \n#with the most important factors that affect loyalty program participation among customers. \n#Use the feature_importances_ method to get the feature importance by using the following code:\n\nclf_Tree.feature_importances_",
            "execution_count": 60,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 60,
                    "data": {
                        "text/plain": "array([0.26796289, 0.39545388, 0.33658323])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#We fed the features to the model in the following order by using the following code(in line 35):\n\n#DF_classification[['EXPERIENCE SCORE','TOTAL SPENT','INCOME']]\n\n#So, the order of importance of the features is as follows:\n\n#1.TOTAL SPENT\n#2.INCOME\n#3.EXPERIENCE SCORE",
            "execution_count": 61,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# #K-fold cross-validation to test which classifier performed best"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.model_selection import KFold",
            "execution_count": 62,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Define a new generic training and testing function with accuracy as the performance metric by using the following code:\n\ndef Training_Testing_Accuracy_Only(model,train_data,train_labels,test_data,test_labels):\n    model.fit(train_data,train_labels)\n    predicted = model.predict(test_data)\n    acc = metrics.accuracy_score(test_labels,predicted)\n    print ('accuracy = '+str(acc*100)+'%')\n    return(acc)\n#the code performs the following functions:\n#It has five arguments as inputs: The classifier model (model), the training data (train_data), the training labels (train_labels), testing data (test_data), and testing labels (test_labels).\n#It trains the model by using the function \u201c.fit()\u201d.\n#It predicts the class labels of the testing feature set and saves them to a list called \u201cpredicted\u201d.\n#It compares the predicted output with the actual labels (\u201ctest_labels\u201d) and calculates the accuracy (\u201cacc\u201d) by using a function that is called \u201cmetrics.accuracy_score()\u201d. Then, it prints the output and returns the accuracy.",
            "execution_count": 63,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Set the number of folds by using the following code:\n\nkf = KFold(n_splits=10)\n\n#We set the folds to 10. Each iteration has 450 training samples and 50 testing samples.",
            "execution_count": 66,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Training and testing the decision tree model by using 10-fold cross-validation\n#Declare an empty list to store the accuracy in each iteration and declare a new decision Tree classifier by using the following code:\n\nclf_Tree=DecisionTreeClassifier(criterion='entropy')\naccuracy_list=[]",
            "execution_count": 67,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Train and test the decision tree model for each fold and get the overall accuracy by using the following code:\n#brekdown of the code is in the ibm module\nfor train_index, test_index in kf.split(DF_classification[['EXPERIENCE SCORE','TOTAL SPENT','INCOME']]):\n    X=DF_classification[['EXPERIENCE SCORE','TOTAL SPENT','INCOME']]\n    Y=DF_classification['LOYALTY GROUP']\n    X_train,X_test=X.iloc[train_index], X.iloc[test_index]\n    Y_train,Y_test=Y.iloc[train_index], Y.iloc[test_index]   \n    accuracy=Training_Testing_Accuracy_Only(clf_Tree,X_train,Y_train,X_test,Y_test)\n    accuracy_list.append(accuracy) \nprint(\"overall_accuracy is %\",100 * sum(accuracy_list)/len(accuracy_list))",
            "execution_count": 68,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "accuracy = 76.0%\naccuracy = 72.0%\naccuracy = 72.0%\naccuracy = 66.0%\naccuracy = 70.0%\naccuracy = 84.0%\naccuracy = 70.0%\naccuracy = 74.0%\naccuracy = 72.0%\naccuracy = 76.0%\noverall_accuracy is % 73.2\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Training and testing the K-Nearest Neighbor classifier with a 10-fold cross-validation \n#and finding the optimum K_neighbors\n#Declare an empty list to store the accuracy for each iteration of K_neighbors by using the following code:\naccuracy_list_for_each_K_neighbours=[]",
            "execution_count": 69,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Train and test the KNN classifier by using two loops: An outer loop to iterate over the values of K neighbors 1 - 14 and an inner loop for training and testing the model by using cross-validation by using the following code:\n#breakdown of the code is in the ibm module\nfor k_neighbours in range(1,15):\n    clf_NN = KNeighborsClassifier(n_neighbors=k_neighbours)\n    accuracy_list_k_fold = []\n    for train_index, test_index in kf.split(DF_classification[['EXPERIENCE SCORE','TOTAL SPENT','INCOME']]):\n        X=DF_classification[['EXPERIENCE SCORE','TOTAL SPENT','INCOME']]\n        Y=DF_classification['LOYALTY GROUP']\n        X_train,X_test=X.iloc[train_index], X.iloc[test_index]\n        Y_train,Y_test=Y.iloc[train_index], Y.iloc[test_index]    \n        accuracy=Training_Testing_Accuracy_Only(clf_NN,X_train,Y_train,X_test,Y_test)\n        accuracy_list_k_fold.append(accuracy)\n    accuracy_list_for_each_K_neighbours.append(100 * sum(accuracy_list_k_fold)/len(accuracy_list_k_fold))\n    print(\"Overall Accuracy for K_neighbours=\",k_neighbours,\"is\",accuracy_list_for_each_K_neighbours[k_neighbours-1])",
            "execution_count": 70,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "accuracy = 64.0%\naccuracy = 64.0%\naccuracy = 66.0%\naccuracy = 64.0%\naccuracy = 82.0%\naccuracy = 68.0%\naccuracy = 70.0%\naccuracy = 64.0%\naccuracy = 76.0%\naccuracy = 68.0%\nOverall Accuracy for K_neighbours= 1 is 68.6\naccuracy = 74.0%\naccuracy = 60.0%\naccuracy = 72.0%\naccuracy = 74.0%\naccuracy = 74.0%\naccuracy = 78.0%\naccuracy = 70.0%\naccuracy = 72.0%\naccuracy = 82.0%\naccuracy = 76.0%\nOverall Accuracy for K_neighbours= 2 is 73.2\naccuracy = 72.0%\naccuracy = 64.0%\naccuracy = 68.0%\naccuracy = 70.0%\naccuracy = 78.0%\naccuracy = 78.0%\naccuracy = 70.0%\naccuracy = 70.0%\naccuracy = 76.0%\naccuracy = 76.0%\nOverall Accuracy for K_neighbours= 3 is 72.20000000000002\naccuracy = 82.0%\naccuracy = 66.0%\naccuracy = 72.0%\naccuracy = 74.0%\naccuracy = 80.0%\naccuracy = 82.0%\naccuracy = 70.0%\naccuracy = 76.0%\naccuracy = 78.0%\naccuracy = 78.0%\nOverall Accuracy for K_neighbours= 4 is 75.80000000000001\naccuracy = 78.0%\naccuracy = 64.0%\naccuracy = 80.0%\naccuracy = 74.0%\naccuracy = 80.0%\naccuracy = 76.0%\naccuracy = 74.0%\naccuracy = 72.0%\naccuracy = 72.0%\naccuracy = 80.0%\nOverall Accuracy for K_neighbours= 5 is 74.99999999999999\naccuracy = 76.0%\naccuracy = 66.0%\naccuracy = 74.0%\naccuracy = 72.0%\naccuracy = 80.0%\naccuracy = 76.0%\naccuracy = 74.0%\naccuracy = 74.0%\naccuracy = 78.0%\naccuracy = 84.0%\nOverall Accuracy for K_neighbours= 6 is 75.4\naccuracy = 68.0%\naccuracy = 66.0%\naccuracy = 82.0%\naccuracy = 72.0%\naccuracy = 84.0%\naccuracy = 76.0%\naccuracy = 76.0%\naccuracy = 74.0%\naccuracy = 76.0%\naccuracy = 82.0%\nOverall Accuracy for K_neighbours= 7 is 75.6\naccuracy = 74.0%\naccuracy = 70.0%\naccuracy = 84.0%\naccuracy = 68.0%\naccuracy = 80.0%\naccuracy = 76.0%\naccuracy = 76.0%\naccuracy = 84.0%\naccuracy = 76.0%\naccuracy = 86.0%\nOverall Accuracy for K_neighbours= 8 is 77.39999999999999\naccuracy = 72.0%\naccuracy = 68.0%\naccuracy = 84.0%\naccuracy = 68.0%\naccuracy = 84.0%\naccuracy = 76.0%\naccuracy = 76.0%\naccuracy = 80.0%\naccuracy = 76.0%\naccuracy = 86.0%\nOverall Accuracy for K_neighbours= 9 is 76.99999999999999\naccuracy = 76.0%\naccuracy = 70.0%\naccuracy = 82.0%\naccuracy = 68.0%\naccuracy = 82.0%\naccuracy = 80.0%\naccuracy = 78.0%\naccuracy = 78.0%\naccuracy = 76.0%\naccuracy = 86.0%\nOverall Accuracy for K_neighbours= 10 is 77.60000000000001\naccuracy = 74.0%\naccuracy = 70.0%\naccuracy = 84.0%\naccuracy = 68.0%\naccuracy = 82.0%\naccuracy = 76.0%\naccuracy = 78.0%\naccuracy = 80.0%\naccuracy = 76.0%\naccuracy = 82.0%\nOverall Accuracy for K_neighbours= 11 is 77.0\naccuracy = 76.0%\naccuracy = 70.0%\naccuracy = 78.0%\naccuracy = 68.0%\naccuracy = 80.0%\naccuracy = 78.0%\naccuracy = 80.0%\naccuracy = 80.0%\naccuracy = 76.0%\naccuracy = 84.0%\nOverall Accuracy for K_neighbours= 12 is 77.0\naccuracy = 76.0%\naccuracy = 72.0%\naccuracy = 82.0%\naccuracy = 70.0%\naccuracy = 82.0%\naccuracy = 78.0%\naccuracy = 78.0%\naccuracy = 80.0%\naccuracy = 74.0%\naccuracy = 82.0%\nOverall Accuracy for K_neighbours= 13 is 77.4\naccuracy = 76.0%\naccuracy = 68.0%\naccuracy = 80.0%\naccuracy = 68.0%\naccuracy = 80.0%\naccuracy = 78.0%\naccuracy = 72.0%\naccuracy = 84.0%\naccuracy = 74.0%\naccuracy = 82.0%\nOverall Accuracy for K_neighbours= 14 is 76.20000000000002\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#You can also identify the optimum K from plotting the accuracy list by completing the following steps:\nfrom matplotlib import pyplot as plt\n\n#Plot the result by using the following code:\n\nplt.plot(range(1,15),accuracy_list_for_each_K_neighbours)\nplt.legend(['Accuracy per K neighbours'], loc='upper left')\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"10 k-Fold Accuracy\")\nplt.show()",
            "execution_count": 71,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x288 with 1 Axes>",
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VPXV+PHPyUYIkBDCFrYEZN9JgoJSQRBFxAVR1LogtIq2gvRX27rW7alV6/NYte6CSKuIoKB1VyJa1AJJANnCnkDCEsgeICHJnN8fM8SASZgsM5Mw5/16zSszd2buPdnm3PtdzldUFWOMMf4rwNcBGGOM8S1LBMYY4+csERhjjJ+zRGCMMX7OEoExxvg5SwTGGOPnLBEYY4yf81giEJE+IrKu0q1AROaIyFAR+a9rW5KInO2pGIwxxpyeeGNCmYgEApnAOcBrwDOq+qmITAT+qKpjPB6EMcaYKgV56TjjgJ2qmi4iCoS7tkcA+0735rZt22psbKwHwzPGmDNPcnLyYVVtd7rXeeuKYB6Qoqr/EJF+wOeA4GyaOldV06t4z23AbQDdunWLT0//2UuMMcbUQESSVTXhdK/zeGexiIQAlwOLXZvuAH6nql2B3wFzq3qfqr6qqgmqmtCu3WkTmjHGmDryxqihS3BeDRx0PZ4GvO+6vxiwzmJjjPEhbySC64GFlR7vA0a77o8FtnshBmOMMdXwaGexiIQB44GZlTbfCjwrIkFAMa5+gNoqLS0lIyOD4uLi+gdqjAeEhobSpUsXgoODfR2KMTXyaCJQ1aNA1CnbVgLx9d13RkYGrVq1IjY2FhGp7+6MaVCqSnZ2NhkZGXTv3t3X4RhToyY7s7i4uJioqChLAqZREhGioqLsitU0CU02EQCWBEyjZn+fpqlo0onAGON5ZeUO/r1+H9/vPOzrUIyHWCKop6VLlyIipKam+joUn5s/fz533nknAA6Hg2nTpjFjxgzqO2kxKSmJ2bNn1/iatLQ0Bg4cWOVzY8aMISkpqV4x+KsVW7O45Nn/MGvhWn752iqmv7Ga7QcLfR2WaWCWCOpp4cKFjBo1infeecejxykvL/fo/uuirKysyu2qyu23305paSmvv/56vZtIEhISeO655+q1j4amqjgcDl+H4TFbDxRy87zV3PLGGo6XO3jxhjjum9iXpLRcJjz7Hx5ctpHsohJfh2kaiCWCeigqKuK7775j7ty5P0sETz31FIMGDWLIkCHcc889AOzYsYMLL7yQIUOGEBcXx86dO1mxYgWTJk2qeN+dd97J/PnzAYiNjeXRRx9l1KhRLF68mNdee43hw4czZMgQpkyZwtGjRwE4ePAgkydPZsiQIQwZMoTvv/+eBx98kGeffbZiv/fff//PPkzT0tLo27cv06ZNY/DgwVx99dUV+0xOTmb06NHEx8dz8cUXs3//fsB5dn3fffcxevTok/Zf2V133UV2djYLFiwgIODnf2KxsbE89NBDxMXFMWjQoIqrqSNHjjBjxgyGDx/OsGHD+OCDDwBO+hkdOnSI8ePHExcXx8yZM4mJieHwYWeTRXl5ObfeeisDBgzgoosu4tixYxXH/Ne//sW5557LwIEDWb16NQA5OTlceeWVDB48mBEjRvDjjz8C8PDDD/P0009XvHfgwIGkpaWRlpZGv379+M1vfkNcXBx79+7llltuYeDAgQwaNIhnnnmmyp9HU3K4qIT7l27gkme/Ze2eXB64tB9f/O58Jg6K5rbzz2LFH8ZwwzndeHv1Hsb8bQWvfLOTkrLGd5JiasdbRec86pF/b2LzvoIG3Wf/TuE8dNmAGl+zbNkyJkyYQO/evWnTpg0pKSnExcXx6aefsmzZMlatWkVYWBg5OTkA3HDDDdxzzz1MnjyZ4uJiHA4He/furfEYoaGhrFy5EoDs7GxuvfVWAB544AHmzp3LrFmzmD17NqNHj2bp0qWUl5dTVFREp06duOqqq7jrrrtwOBy88847FR+AlW3dupW5c+dy3nnnMWPGDF588UXuuusuZs2axQcffEC7du1YtGgR999/P/PmzQMgLy+Pb775psp43377bfr168eKFSsICqr+z6tt27akpKTw4osv8vTTT/P666/zl7/8hbFjxzJv3jzy8vI4++yzufDCC0963yOPPMLYsWO59957+eyzz3j11Vcrntu+fTsLFy7ktddeY+rUqbz33nvceOONgDPJfP/993z77bfMmDGDjRs38tBDDzFs2DCWLVtGYmIiN998M+vWravx97F161beeOMNXnzxRZKTk8nMzGTjxo0VP5ealJY7KHcoocGBNb7OF4pLy3njuzRe+HoHx0rLuXlkLLPH9aJNi5CTXhfVshmPXjGQm0fG8Pgnqfz101T+tSqdeyb0Y+Kgjn7XQd6Yf6e1cUYkAl9ZuHAhc+bMAeC6665j4cKFxMXF8dVXXzF9+nTCwsIAaNOmDYWFhWRmZjJ58mTA+QHvjmuvvbbi/saNG3nggQfIy8ujqKiIiy++GIDExEQWLFgAQGBgIBEREURERBAVFcXatWs5ePAgw4YNIyoq6mf779q1K+eddx4AN954I8899xwTJkxg48aNjB8/HnCeaUdHR1cZ06ni4uJITU1l9erVFfutylVXXQVAfHw877/vrDjyxRdf8OGHH1acjRcXF7Nnz56T3rdy5UqWLl0KwIQJE4iMjKx4rnv37gwdOrRiv2lpaRXPXX/99QCcf/75FBQUkJeXx8qVK3nvvfcAGDt2LNnZ2eTn51cbM0BMTAwjRowAoEePHuzatYtZs2Zx6aWXctFFF1X7PlXlV28mkZSWwyUDo7k6vgvndG9DQIBvPzhVlY9+3M8Tn6aSmXeMC/u1555L+tGzfcsa39ezfSvm3TKc/2w/xF8+3sJv304hISaSByb1Z2jX1l6K3nc27ytgcfJePli3j2ZBAbx3x7l0at3c12HV2RmRCE535u4J2dnZJCYmsnHjRkSE8vJyRISnnnoKVf3ZmVF1HaZBQUEntTWfOu68RYsWFfdvueUWli1bxpAhQ5g/fz4rVqyoMcZf//rXzJ8/nwMHDjBjxowqX3NqnCKCqjJgwAB++OGHKt9TOaZT9e3bl0cffZSpU6fy+eefM2BA1b+bZs2aAc7EdaKvQVV577336NOnz0mvPXjwYMX9mjqeT+zzxH4rNw1V932eSkRq/J1U/t4jIyNZv349n3/+OS+88ALvvvtuxVXTqT7ZcIBvtx1iZI8ovth0gPdSMugS2ZwpcV24Or4LXduEVft9eUrKnlwe+2gza/fk0S86nKeuHsx5PdvWah+/6NWOj2e3ZXHSXp7+YhtXvvAdVw7txB8m9KVzE/5grEp2UQkfrNvHkuQMNu8vICQwgAv6tuP7Hdnc8sZqFt9+LhHNm+YscusjqKMlS5Zw8803k56eTlpaGnv37qV79+6sXLmSiy66iHnz5lW0t+fk5BAeHk6XLl1YtmwZACUlJRw9epSYmBg2b95MSUkJ+fn5LF++vNpjFhYWEh0dTWlpKW+99VbF9nHjxvHSSy8BzrP3ggJnM9nkyZP57LPPWLNmTcXVw6n27NlT8YF/ouO7T58+HDp0qGJ7aWkpmzZtcvtnc+655/Lyyy9z6aWX/uyMviYXX3wxzz//fMUH9Nq1a3/2mlGjRvHuu+8CziuI3Nxct/a9aNEiwHlFceKK6fzzz6/4Oa5YsYK2bdsSHh5ObGwsKSkpAKSkpLB79+4q93n48GEcDgdTpkzhscceq3jPqY4eL+MvH2+mX3Q4//zV2ay+/0KevW4o3du24LnE7fziqa+59pUfWJy0lyMlVXfAN6SM3KPMXriWq178nozcYzw1ZTAfzRpV6yRwQmCAcN3Z3VjxhzHceUFPPt14gLFPr+Dpz7dS5IXvx5NKyx18sekAty1I4pzHl/PoR5sJChQevWIAq+4bxys3JfDKzfHsPnyE2xYkUVzaNPtLzogrAl9YuHBhRSfwCVOmTOHtt9/mpZdeYt26dSQkJBASEsLEiRN5/PHH+ec//8nMmTP585//THBwMIsXL6ZHjx5MnTqVwYMH06tXL4YNG1btMR977DHOOeccYmJiGDRoEIWFzmF8zz77LLfddhtz584lMDCQl156iZEjRxISEsIFF1xA69atCQysug2zX79+vPnmm8ycOZNevXpxxx13EBISwpIlS5g9ezb5+fmUlZUxZ86cas/uqzJp0iQOHTrEhAkT+M9//lNls9SpHnzwQebMmcPgwYNRVWJjY/noo49Oes1DDz3E9ddfz6JFixg9ejTR0dG0atWKoqKiGvcdGRnJueeeS0FBQcVZ+8MPP8z06dMZPHgwYWFhvPnmm4Dz97hgwQKGDh3K8OHD6d27d5X7zMzMZPr06RVXD3/961+rfN2LX+9kX34xz14/jKDAAIIC4YqhnbliaGf25R1j6dpMliRn8IclP/LQh5uYOMjZdHR2bMM2HRUWl/LSip28vnI3AQKzx/Zk5uizaNGsYT4GWjYL4u6L+3D9Od3422ep/OPrHbyzZi93X9SbaxK6EujjZrDa2LyvgCXJGXywLpPsI8dp27IZM0Z1Z0pcF/p0bHXSa889qy1PXzOEu95Zx+8Xr+f564b5vMmvtryyME19JSQk6KnjwLds2UK/fv18FFHT4HA4iIuLY/HixfTq1etnz6elpTFp0qSKzs6moKSkhMDAQIKCgvjhhx+44447TtvB60sbNm5iysI9TBzUkb9fV32SV1VS9uSyOCmDj37cT1FJGV3bOJuOpsTVr+morNzBu0kZ/N+XWzlcdJyrhnXm7ov7eLxNe+2eXP7n4y0kp+fSt2MrHri0P6N61e2qwxtObfoJDhTG9+/A1fFdOL9XO4ICa25AefXbnTz+SSq/GtWdByf191LUNXN3YRq7IjhDbd68mUmTJjF58uQqk0BTtWfPHqZOnYrD4SAkJITXXnvN1yHVKP9YKcGBwr0Taz5pERHiY9oQH9OGhy4bwOebDrAkOYNnl2/n719tZ0SPNlwd35VLBnas1Rn8t9ucnblbDxZydmwb5t3Sj8FdvNOZO6xbJEtuH8knGw7w10+3cOPcVYzr2557J56+M9pbSssdfJ2axZLkDBJTsyhzKIM6R/DI5QO4fEgnIk8ZNVWTW3/Rg315xcxduZvoiFB+/YseHoy8YdkVgTEeUnCslFVrN7CrNIKZo8+q0z4y846xNCWDJckZpGUfJSwk0K2mo+0HC/nLJ1tYsfUQ3dqEcd/Evlw8wHfDO4tLy3nz+zT+kbiDo6Xl3HhON+66sPfPhqd6y5b9zqafZWtPNP2EMHlYZ6bEd6Fvx/DT76Aa5Q5l1sIUPtlwgOevH8ZlQzo1YNS15+4VQZNOBH379vW7ccumaXA4lK0HC9ifvotRCUMICarfuAxVJTk9lyXJNTcdZReV8MxX21i4ei9hIYHcNa4XN42MoVlQ4xjnnl1Uwt+/2s7bq/cQFhLI7LG9uPlc78SXc+Q4H6xz9sds2uds+rmwn6vpp3c7gk/T9OOu4tJybp67mnV783hzxtmMPOv0/WOecsYngt27d9OqVSsrRW0apYP5x8g4kIUeLyZhUJ/Tv6EWjh0v57NN+1mSnMH3O7NRhZE9ohjcNYK3/7uHo6Xl3DQipsoJYY3F9oOFPP7JFr52XbHcPvosWod5ZujlsePlfLH5AImpWZSWO5t+ro7vUuumn9rIP1rK1S9/z4GCYhbfPrJeVxn1ccYnAluhzDRW5Q5lf34xR8uFiSMGenSFsozcoyxNyWRJSgbp2UfdnhDWWFTuw/Ckhmr6qY3MvGNc9eJ3CMLS355LdIT351Wc8YnAmMbqt2+n8NXmg3z1/0Z7baKYqlYMc2xqyh3KrkNFODz0URQgENu2RYM1/dTG5n0FTH3lBzq3bs67t4/0+oQzGzVkjA98v+MwH/+4nzkX9vLqbGERaZJJAJwT0np1aHX6FzZB/TuF88pN8dzyxmpuW5DEgl+d3Wj6ayqzmcXGNJDScgcP/3sTXSKbc3sdRwmZM895PZ0TzlbtzuH3767H4alLn3qwKwJjGsiCH9LZdrCIV2+Kb/LVKE3DumJoZ/bnF/PEp6l0DA/lgUYy4ewESwTGNIBDhSX8/cttnN+7HeP7d/B1OKYRmnl+Dw7kF/P6yt1Et27Or0Z193VIFSwRGNMAnvwsleKych66rL8NZzZVEhEenNSfA/nF/M/Hm+kQ3oxJg3074ewE6yMwpp5OTPSaMao7Z7VrGsM2jW8EBgh/v24oCTGR/L9F6/nvrmxfhwRYIjCmXsodysMfbqJDeDNmjT1zajoZzwkNDuS1mxPoFhXGrQuS2HrAs3Mo3GGJwJh6WLRmLxsy87lvYj9aNlA5Z3Pmax0Wwvzpw2keHMgtb6xmf/6x07/JgywRGFNHeUeP87fPUzm7exsu93FxMdP0dIkM443pwyksLmP6G2soKC71WSyWCIypo//9Yhv5x0p55PIB1kFs6mRApwhevjGeHVlFzFyQTEmZb1Y4s0RgTB1s2pfPW6vSuXlkLP2ifVNQzJwZRvVqy9+uGcwPu7K5e/GPPplwZo2axtSSqvLQB5toHRbC7y6sehlLY2pj8rAuHMgv4cnPUomOCOW+0yxk1NAsERhTS8vWZZKUnsuTUwYR4aHSycb/3D66B/vzj/Hqt7voGB7KDC9OOLNEYEwtFBaX8vgnqQzpEsE18V19HY45g4gID102gIMFxTz28WY6RoQycVC0V45tfQTG1MLziTs4VFjCI1cMrHaZSGPqKjBAePa6YcR3i2TOonWs8tKEM0sExrhpR1Yh81bu5tqErgzt6p0F4I3/OTHhrGtkc25dkMQ2Dy/aA5YIjHGLqvLwh5tpHhLIHyY07NKTxpwqskUI86efTbeoMErLHR4/nscSgYj0EZF1lW4FIjLH9dwsEdkqIptE5ClPxWBMQ/l80wFW7jjM78f3brILwJimpWubMP595ygGdIrw+LE81lmsqluBoQAiEghkAktF5ALgCmCwqpaISHtPxWBMQzh2vJzHPtpC346tuHFEjK/DMX7EWxMVvdU0NA7YqarpwB3AE6paAqCqWV6KwZg6eembnWTmHePhywcQ5IN1b43xNG/9VV8HLHTd7w38QkRWicg3IjK8qjeIyG0ikiQiSYcOHfJSmMacbE/2UV7+ZieXD+nEiB5Rvg7HGI/weCIQkRDgcmCxa1MQEAmMAP4AvCtVXP+o6quqmqCqCe3atfN0mMZU6bGPNxMUIF6f6WmMN3njiuASIEVVD7oeZwDvq9NqwAG09UIcxtTKiq1ZfLn5ILPG9qJjRKivwzHGY7yRCK7np2YhgGXAWAAR6Q2EAIe9EIcxbispK+eRf2+me9sWzBgV6+twjPEojyYCEQkDxgPvV9o8D+ghIhuBd4Bpqur9cnt+bO2eXEb/7Wv+vX6fr0NptOatTGP34SM8dFl/mgUF+jocYzzKo7WGVPUoEHXKtuPAjZ48rqnZkuQM0rOPMmvhWlbtzuaBS/sTGmwfdiccyC/m+cTtjO/fgTF9bHSzOfNZ0Tk/o6okpmYxrm97erZvySvf7iIlPY8Xboije9sWvg6vUXj8ky2UOZQHL+3v61CM8QobFO1ntuwvZH9+MRcP6Mi9E/sxd1oC+/KPcdnzK62pCPjvrmw+XL+P20efRbeoMF+HY4xXWCLwM4mpzsFbY/o6h+SO69eBj2f/gt4dWjJr4VoeWLaB4lLfLJfnKyVl5WzMzOfdpL3cv3QDnVs3547RZ/k6LGO8xpqG/Mzy1CyGdImgfaufhkN2bt2cRTNH8vTnWyuail68IY7YM7CpKO/ocTbvL2DzvoKKrzuyiihzLQ/YqlkQz/9yGM1DrM/E+A9LBH4ku6iEdXvzmDPu58srBgcGcO/EfpzdvQ2/X7yeSc+v5Ikpg5g0uJMPIq0/VSUj9xibKn3gb9lfQGbesYrXdAhvRv/ocMb1a0//6Aj6dwonpk2YrTNg/I4lAj+yYushVGFs3+pHwpxoKpr1dgp3vr2WVbtyuP/Sfo16VNHxMgfbsworzvI3uT70C4vLAAgQOKtdSxJiI7k5Oob+ncLpFx1uVUSNcbFE4EcSU7No36oZAzqF1/i6nzUV7cnlhV82jqai4tJy1u7JO6l5Z0dWIaXlzqad5sGB9ItuxRVDO1Wc5ffp0MqaeoypgSUCP3G8zMG32w5x6eBot5o+TjQVDY/1fVORqrJubx5LkjP49/p9FLjO9Nu3akb/TuFc0Kcd/TuF0z86nJioFgRa044xtWKJwE8kpeVQWFJWY7NQVS7s34FP7voFd/qgqehgQTFL12ayJDmDHVlFhAYHcMnAaC4bEs2gzq1p18qadoxpCJYI/ERiahYhQQGc17P29f06t27OuzNH8rfPt/Kqh5uKikvL+WrLQZYkZ/DttkM4FIbHRvLklEFMHBRNq9DgBj+mMf7OEoGfSEzNYkSPKFo0q9uvPDgwgPsm9uPsSk1FT04ZzKWDo+sdm6qyPiOfJcl7+XCds+mnU0Qov72gJ1fFdbEZz8Z4mCUCP7DrUBG7Dh9h2rmx9d7Xhf078PHsUdz59lp++3YKq3bHcN/EujUVVdX0M2FAR65J6MrIHlE2jNMYLzltIhCR93BWDP1UVR2eD8k0tMRU52qgte0fqE6XyDBXU1Eqr/1nd0VTUUzU6c/cq2r6SYiJ5ImrBjFxcDTh1vRjjNe5c0XwEjAdeE5EFgPzVTXVs2GZhpSYmkXvDi3p2qbhaueEBAVw/6X9Obt7FHcvXs+k51byRDVNRarKjxn5LK7U9BMdEcpvxvRkSrw1/Rjja6dNBKr6FfCViETgXGTmSxHZC7wG/EtVSz0co6mHwuJSVu/O4de/6OGR/Y+voakoq1LTz/asIpoFBXDJwI5cHd+VkWdF2TBPYxoJt/oIRCQK5xoCNwFrgbeAUcA0YIyngjP195/thylzaIM1C1Xl1Kai5PRc2rdqxjfW9GNMk+BOH8H7QF/gn8Blqrrf9dQiEUnyZHCm/pZvySKieTBx3Vp79DiVm4r+uGQ9OUeOW9OPMU2EO1cE/1DVxKqeUNWEBo7HNKByh7JiaxZj+rQjKNA7FcfH9+9A8gPjAWzUjzFNhDufDv1EpOJ0UkQiReQ3HozJNJD1GXlkHznu0WahqgQEiCUBY5oQdxLBraqad+KBquYCt3ouJNNQvk7NIjBAGN27na9DMcY0Yu4kggARqTi9E5FAIMRzIZmGsnxLFvExkbQOs1+XMaZ67iSCz4F3RWSciIwFFgKfeTYsU1/784+xeX+B15uFjDFNjzudxX8CZgJ3AAJ8AbzuyaBM/Z2YTTzOEoEx5jTcmVDmwDm7+CXPh2MaSuKWLLq2aU7P9i19HYoxppE7bdOQiPQSkSUisllEdp24eSM4UzfFpeV8t/Mw4/p2oFL3jjHGVMmdPoI3cF4NlAEXAAtwTi4zjdQPO7MpLnVY/4Axxi3uJILmqrocEFVNV9WHgbGeDcvUx/LUg4SFBHJOjza+DsUY0wS401lcLCIBwHYRuRPIBOxUs5FSVRK3ZDGqZ1uaBdmC7caY03PnimAOEAbMBuJxFp+b5smgTN2lHihkX34x4/pZrjbGuKfGKwLX5LGpqvoHoAjnugSmETsxbPSCPpYIjDHuqfGKQFXLgXixoSdNRmJqFoO7RNA+PNTXoRhjmgh3+gjWAh+4Vic7cmKjqr7vsahMneQcOU7KnlzuGtfL16EYY5oQdxJBGyCbk0cKKWCJoJFZsTUL1YZbm9gY4x/cmVls/QJNxPLULNq1asbAThG+DsUY04S4s0LZGzivAE6iqjM8EpGpk9JyB99uO8TEgdG2FoAxplbcGT76EfCx67YcCMc5gqhGItJHRNZVuhWIyJxKz98tIioibesavPlJUlouhcVljLVho8aYWnKnaei9yo9FZCHwlRvv2woMdb0nEOdEtKWux12B8cCe2odsqpKYepCQwABG9bS8aoypnbosZNsL6FbL94wDdqpquuvxM8AfqaLJydTN8tQszunRhhbN3On/N8aYn7jTR1DIyR/YB3CuUVAb1+Fc0AYRuRzIVNX1NU1PEJHbgNsAunWrbd7xL2mHj7Dr0BFuHhHj61CMMU2QO01DrepzABEJAS4H7hWRMOB+4CI3jvsq8CpAQkKCXTnU4MRs4rF9O/g4EmNMU+TOegSTRSSi0uPWInJlLY5xCZCiqgeBs4DuwHoRSQO6ACki0rF2YZvKElOz6NW+Jd2iwnwdijGmCXKnj+AhVc0/8UBV84CHanGM63E1C6nqBlVtr6qxqhoLZABxqnqgFvszlRQWl7Jqd7aNFjLG1Jk7iaCq17jVI+lqChqPzUL2mJXbD1NaroyzZiFjTB2584GeJCL/B7yAs9N4FpDszs5V9SgQVcPzse7sx1RveWoWEc2DievW2tehGGOaKHeuCGYBx4FFwLvAMeC3ngzKuMfhUFZszWJ073YEBdZlJLAxxrg3augIcI8XYjG19GNmPoeLjtsiNMaYenFn1NCXItK60uNIEfncs2EZdyRuOUiAwOje7XwdijGmCXOnPaGta6QQAKqai61Z3CgsT80iIaYNrcNCfB2KMaYJcycROESkYmqviMRgpSF87kB+MZv2FXCBrT1gjKknd0YN3Q+sFJFvXI/PB2Z6LiTjjq+3OmcTW/+AMaa+3Oks/kxE4oARgAC/U9XDHo/M1Gj5liy6RDanV/uWvg7FGNPEuTXmUFUPq+pHwGbgdhHZ6NmwTE2KS8v5bsdhxvVtT02F+4wxxh3ujBqKFpE5IrIa2AQE4iwbYXzkh13ZHCstZ2w/m01sjKm/ahOBiNwqIonAN0Bb4NfAflV9RFU3eCtA83OJW7JoHhzIOd3b+DoUY8wZoKY+gheAH4BfqmoSgIjYaCEfU1USU7MY1astocGBvg7HGHMGqKlpqBPwDvB/IrJVRB4Dgr0TVuOXf7SUm+et5qvNB7163G0Hi8jMO8Y4GzZqjGkg1SYCVwfxS6p6Ps6lJvOBLBHZIiKPey3CRmrljsN8u+0QM/+VzLK1mV477vJUZ+Kx+QPGmIbi7qihDFV9WlXjgSuBEs+G1fitScuheXAgw2Mj+d25eJNBAAAVOUlEQVS76/jnD2leOW7iliwGdY6gQ3ioV45njDnz1bpkpapuVdVHPBFMU5KcnsvQrq2ZP/1sxvVtz4MfbOLFFTs8eszcI8dJ2ZPLWLsaMMY0IKtdXAdHSsrYvL+AhNhIQoMDeenGeK4Y2omnPtvKE5+mouqZPvVvth3CoVgiMMY0KLdWGjMnW7c3j3KHkhDrHL4ZHBjAM1OH0rJZEC9/s5PC4lIeu2IgAQENO9lreWoWbVs2Y1DniNO/2Bhj3FRtInCVlaiWqqY0fDhNQ1JaLiIwrNKqYAEBwv9cOZDw5sG8tGInRSVlPH3NEIIbaMGY0nIH32zNYsLAjg2eYIwx/q2mK4L/dX0NBRKA9ThrDQ0GVgGjPBta45WUnkOfDq0IDz15NK2I8KcJfWkVGsRTn22lqLiMF26Ia5Dx/snpuRQUlzHW1iY2xjSwmoaPXqCqFwDpQJyqJrhGDQ0DPNsr2oiVO5S1e/IYHlv9rN7fjOnJY1cOJHFrFre8sZqikrJ6HzcxNYuQwABG9Wpb730ZY0xl7rRb9K1cUkJVNwJDPRdS45Z6oICikjISYiNrfN1NI2J4ZupQ1qTlcsNr/yX3yPF6HTcxNYtzerShZTPr1jHGNCx3EsEWEXldRMaIyGgReQ3Y4unAGqvk9FwA4mNqTgQAVw7rzCs3xrPlQCFTX/mBgwXFdTpmevYRdmQV2WghY4xHuJMIpuOsOnoXMAdnKerpngyqMVuTlkt0RCidWzd36/UX9u/A/OnD2Zd3jKtf/p492UdrfczEVOciNJYIjDGecNpEoKrFqvqMqk523Z5R1bqd2p4BktNyiI+JrNU6AOee1Za3bh1BYXEZV7/8PdsOFtbqmImpWfRs35KYqBa1DdcYY06rpjLUG0Tkx+pu3gyyscjMO8a+/GIS3GgWOtXQrq1ZdNtIAK595Qd+zMhz631FJWX8d1e2FZkzxnhMTT2Pk7wWRRORlJYDUDGRrLb6dGzF4ttHcuPcVfzytVW8Pi2BET2ianzPyu2HKS1XaxYyxnhMTcNH00/cgGJgkOt2zLXN7ySn59IiJJC+HVvVeR8xUS1YPPNcoiNCmTZvNYmpNZexTkw9SHhokFud08YYUxfuLFU5FVgNXANMBVaJyNWeDqwxSkrLZVi3SILqOVu4Y0Qoi2aOpHeHVty2IJkP1lVdxtrhUBJTDzG6T/t6H9MYY6rjzqfL/cBwVZ2mqjcDZwMPejasxqewuJTUAwWnnT/grjYtQnj71nOIi4lkzqJ1vLXq5xdZGzLzOVxUYv0DxhiPcicRBKhqVqXH2W6+74yydk8eDoWEmIZbJ7hVaDALZpzNmN7tuH/pRl7+ZudJzy9PzSJAYHTvdg12TGOMOZU7H+ificjnInKLiNwCfAx84tmwGp+k9FwCBIZWKjTXEEKDA3nlpgQmDY7miU9Teeqzn8pYf52aRXxMJJEtQhr0mMYYU9lp6xWo6h9EZApwHs6ic6+q6lKPR9bIJKXl0C863CMlHkKCAnj2umG0Cg3mxRU7KSgu5bcX9GRDZj5/nNCnwY9njDGV1VSGeoSq/hdAVd8D3vNaVI1MWbmDdXvzmJrQ1WPHCAwQHp88kPDQIF75dhff7cgGYJxVGzXGeFhNTUMvnrgjIj94IZZGa8v+Qo4eL/f4EE4R4Z5L+vKHi/uw+/AROrduTu8OLT16TGOMqamdo3INBb9eKX1NxUQyz4/lFxF+e0FPerRtQcvQoFqVsjDGmLqoKREEiEgkzquGE/crPpVUNaemHYtIH2BRpU09gD8DnYHLgOPATmC6qrpXb8FHktNz6dy6OdER7hWaawiXDIr22rGMMf6tpkQQASTz04d/5aUpFecHe7VUdSuudQtEJBDIBJYCfYB7VbVMRJ4E7gX+VKfovUBVSUrPOW0pCGOMaaqqTQSqGtuAxxkH7HSVpqg8c+q/QKOepZyRe4yDBSV1KjRnjDFNQa0mhonIw3U8znXAwiq2zwA+reZYt4lIkogkHTp0qI6Hrb+k9PoVmjPGmMautjOEL6/tAUQkxPW+xadsvx8oA96q6n2q+qprneSEdu18N7M2KS2XVs2C6N2h7oXmjDGmMavt7Ki6DGG5BEhR1YoymyIyDWeZ63F6YhptI5WUlsuwmEgCA2z0jjHmzORO9dHKbSLxrm3da3GM66nULCQiE3B2Dl+uqrVft9GL8o+Vsi2rkOHWP2CMOYO50zT0bxEJB1BVh4j0B/7tzs5FJAwYD7xfafM/gFbAlyKyTkRermXMXpOyJxdViPfC/AFjjPEVd5qGHseZDC7FOfRzAXCDOzt3nfFHnbKtZ22D9JXktFwCA4ShXRu20JwxxjQm7hSd+1hEgoEvcJ7JX6mq2z0eWSOwJi2HgZ3CCQtp+EJzxhjTWNRUdO55nBPHTggHdgGzRARVne3p4HyptNzB+ow8fnl2jK9DMcYYj6rpVDfplMfJngyksdm0r4DiUodX6gsZY4wv1TSz+E1vBtLYJJ0oNGcjhowxZzi/W3LSXUlpuXRrE0b7cL8uvGqM8QOWCKrgLDSXa1cDxhi/YImgCunZRzlcVGLzB4wxfqHaRCAiESLyhIikiki267bFte2MHliflJ4LwHArNGeM8QM1XRG8C+QCY1Q1SlWjgAtc2xbX8L4mLzk9h/DQIHq2s2UijTFnvpoSQayqPqmqB05sUNUDqvok0M3zofnOmrRc4mMiCbBCc8YYP1BTIkgXkT+KSIcTG0Skg4j8Cdjr+dB8I+/ocXZkFdn6A8YYv1FTIrgWZ52gb0QkR0RygBVAG2CqF2LziWRX/4CNGDLG+IuaJpTl4iwX3WjXE/aENWm5BAcKQ6zQnDHGT9Rp+KiITG/oQBqL5PQcBnaOIDQ40NehGGOMV9R1HsEjDRpFI1FSVs76jHxrFjLG+JWaqo/+WN1TQIdqnmvSNmbmc7zMQXyMdRQbY/xHTdVHOwAX45w3UJkA33ssIh9KSnN1FNuMYmOMH6kpEXwEtFTVdac+ISIrPBaRDyWl59K9bQvatmzm61CMMcZraho19KsanvulZ8LxHVUlOT2XsX3b+zoUY4zxKis657Lr8BFyjhxnuDULGWP8jCUCl2RX/4B1FBtj/I0lApc1aTlEhgVzVrsWvg7FGGO8yhKBS3J6LvExbRCxQnPGGP9iiQDILiph1+EjNmzUGOOXLBHw00I0NqPYGOOPLBHgbBYKCQxgYOcIX4dijDFeZ4kASErLYXAXKzRnjPFPfp8IikvL2ZCZbwvVG2P8lt8ngh8z8iktVxJs/oAxxk/5fSJISs8BIN46io0xfsoSQVouZ7VrQZsWIb4OxRhjfMKvE4HD4Sw0Z81Cxhh/5teJYOehIvKPldpEMmOMX/PrRLCmYiEauyIwxvgvv04ESek5RLUIITYqzNehGGOMz3gsEYhIHxFZV+lWICJzRKSNiHwpIttdX33WLpOcnktCbKQVmjPG+DWPJQJV3aqqQ1V1KBAPHAWWAvcAy1W1F7Dc9djrsgqLSc8+ah3Fxhi/562moXHATlVNB64A3nRtfxO40ksxnKRiIRrrKDbG+DlvJYLrgIWu+x1UdT+A62uViwSLyG0ikiQiSYcOHWrwgJLSc2kWFMDATlZozhjj3zyeCEQkBLgcWFyb96nqq6qaoKoJ7dq1a/C4ktJzGdK1NSFBft1fbowxXrkiuARIUdWDrscHRSQawPU1ywsxnOTY8XI2Zebb+gPGGIN3EsH1/NQsBPAhMM11fxrwgRdiOMm6vXmUOZThNn/AGGM8mwhEJAwYD7xfafMTwHgR2e567glPxlCVZFehubhudkVgjDFBnty5qh4Fok7Zlo1zFJHPrEnLpXeHlkSEBfsyDGOMaRT8rqfU4VBS9uQSb/MHjDEG8MNEsC2rkMLiMobb/AFjjAH8MBFUFJqzKwJjjAH8MBEkp+XQrlUzurZp7utQjDGmUfC7RJCUnstwKzRnjDEV/CoRHMgvJiP3mHUUG2NMJX6VCE4sVG8zio0x5if+lQjScmkeHEj/TuG+DsUYYxoN/0oE6TkM7dqa4EC/+raNMaZGfvOJeKSkjC37C22hemOMOYXfJIJ1e/Mod6gtVG+MMafwm0SwJi0HERjWrbWvQzHGmEbFbxJBcnoufTq0IjzUCs0ZY0xlfpEIysodpKTn2voDxhhTBb9IBKkHCjlyvNw6io0xpgp+kQiS052F5uJtIpkxxvyMXySCpPRcoiNC6dzaCs0ZY8yp/CMRpOUQH2OF5owxpipnfCLIzDvG/vxiqy9kjDHVOOMTQVKaq9CcjRgyxpgq+UEiyKVFSCB9O7bydSjGGNMonfmJID2XYd0iCbJCc8YYU6Uz+tOxoLiUrQcKbNioMcbU4IxOBGv35OFQbEaxMcbU4IxOBMlpOQQIDLVCc8YYU60zOhF0jmzO1fFdaNksyNehGGNMo3VGf0JeO7wb1w7v5uswjDGmUTujrwiMMcacniUCY4zxc5YIjDHGz1kiMMYYP2eJwBhj/JwlAmOM8XOWCIwxxs9ZIjDGGD8nqurrGE5LRA4B6b6OoxptgcO+DqIOmmrcYLH7isXuG/WJPUZV253uRU0iETRmIpKkqgm+jqO2mmrcYLH7isXuG96I3ZqGjDHGz1kiMMYYP2eJoP5e9XUAddRU4waL3Vcsdt/weOzWR2CMMX7OrgiMMcbPWSKoAxHpKiJfi8gWEdkkInf5OqbaEpFAEVkrIh/5OpbaEJHWIrJERFJdP/+Rvo7JXSLyO9ffy0YRWSgiob6OqToiMk9EskRkY6VtbUTkSxHZ7vra6BYDrybuv7n+Xn4UkaUi0iiXLKwq9krP3S0iKiJtPXFsSwR1Uwb8XlX7ASOA34pIfx/HVFt3AVt8HUQdPAt8pqp9gSE0ke9BRDoDs4EEVR0IBALX+TaqGs0HJpyy7R5guar2Apa7Hjc28/l53F8CA1V1MLANuNfbQblpPj+PHRHpCowH9njqwJYI6kBV96tqiut+Ic4Po86+jcp9ItIFuBR43dex1IaIhAPnA3MBVPW4qub5NqpaCQKai0gQEAbs83E81VLVb4GcUzZfAbzpuv8mcKVXg3JDVXGr6heqWuZ6+F+gi9cDc0M1P3OAZ4A/Ah7r0LVEUE8iEgsMA1b5NpJa+TvOPyyHrwOppR7AIeANV7PW6yLSwtdBuUNVM4GncZ7V7QfyVfUL30ZVax1UdT84T4aA9j6Opy5mAJ/6Ogh3icjlQKaqrvfkcSwR1IOItATeA+aoaoGv43GHiEwCslQ12dex1EEQEAe8pKrDgCM0zuaJn3G1p18BdAc6AS1E5EbfRuVfROR+nM26b/k6FneISBhwP/BnTx/LEkEdiUgwziTwlqq+7+t4auE84HIRSQPeAcaKyL98G5LbMoAMVT1x9bUEZ2JoCi4EdqvqIVUtBd4HzvVxTLV1UESiAVxfs3wcj9tEZBowCbhBm86Y+bNwnjisd/2/dgFSRKRjQx/IEkEdiIjgbKfeoqr/5+t4akNV71XVLqoai7OzMlFVm8SZqaoeAPaKSB/XpnHAZh+GVBt7gBEiEub6+xlHE+noruRDYJrr/jTgAx/G4jYRmQD8CbhcVY/6Oh53qeoGVW2vqrGu/9cMIM71f9CgLBHUzXnATTjPpte5bhN9HZSfmAW8JSI/AkOBx30cj1tcVzFLgBRgA87/vUY721VEFgI/AH1EJENEfgU8AYwXke04R7E84csYq1JN3P8AWgFfuv5XX/ZpkNWoJnbvHLvpXCUZY4zxBLsiMMYYP2eJwBhj/JwlAmOM8XOWCIwxxs9ZIjDGGD9nicB4nauK4v9Weny3iDzcQPueLyJXN8S+TnOca1zVT79ugH09KiIXnuY1D4vI3VVsj62qWqUxtWGJwPhCCXCVp0rq1pWIBNbi5b8CfqOqF9T3uKr6Z1X9qr77qYtafs/mDGWJwPhCGc7JVL879YlTz+hFpMj1dYyIfCMi74rINhF5QkRuEJHVIrJBRM6qtJsLReQ/rtdNcr0/0FWXfo2rLv3MSvv9WkTexjnR69R4rnftf6OIPOna9mdgFPCyiPztlNePEZEV8tOaCW+5ZhIjIvGu7yFZRD6vVK6h4nsWkYmu960Ukefk5PUi+rv2vUtEZlfaHiQib7q+ryWuGjWIyDhXcb4N4qx138y1PU1E/iwiK4FrRGS2iGx2vf8dN35/5kyjqnazm1dvQBEQDqQBEcDdwMOu5+YDV1d+revrGCAPiAaaAZnAI67n7gL+Xun9n+E8yemFc1p+KHAb8IDrNc2AJJx1XMbgLF7XvYo4O+EsDdEOZ8G7ROBK13MrcK4tcOp7xgD5OOvCBOCcKToKCAa+B9q5XnctMK/y9+yKc++JWICFwEeu+w+73t8MaAtku/YZi7M88Xmu181z/TxP7Ku3a/sCnMURcf3c/1gp5n1AM9f91r7++7Cb9292RWB8Qp3VWhfgXKzFXWvUuRZECbATOFHGeQPOD8QT3lVVh6puB3YBfYGLgJtFZB3OkuFROBMFwGpV3V3F8YYDK9RZKO5E1crz3YhztapmqKoDWOeKrQ8wEFeZA+ABfl4Xvy+wq1IsC095/mNVLVHVwzgLvnVwbd+rqt+57v8LZ+Lpg7PI3TbX9jdPiX1Rpfs/4izbcSPOqzXjZ4J8HYDxa3/HWXvnjUrbynA1WbqaVEIqPVdS6b6j0mMHJ/8tn1o3RQEBZqnq55WfEJExOK8IqiKn/Q6qVjnOcldsAmxS1ZqW1jzd8araL1T//dak8vd8Kc4kcTnwoIgM0J8WcjF+wK4IjM+oag7wLs6O1xPSgHjX/StwNn/U1jUiEuDqN+gBbAU+B+5wlQ9HRHrL6Re1WQWMFpG2rk7V64Fv6hAPrhjaiWuNZREJFpEBp7wmFeghzsWOwNl85I5u8tPazdcDK137ihWRnq7tN1UVu4gEAF1V9WucixW1Blq6eVxzhrArAuNr/wvcWenxa8AHIrIa57q41Z2t12Qrzg+9DsDtqlosIq/jbKJJcV1pHOI0Sy2q6n4RuRf4GucZ9ieqWqfSy6p63NUh/JyIROD83/s7sKnSa46JyG+Az0TkMLDazd1vAaaJyCvAdpwL9xSLyHRgsTiXxlwDVFV1MxD4lysmAZ7RprX8p2kAVn3UmEZERFqqapErWb0AbFfVZ3wdlzmzWdOQMY3Lra7O5E04R1S94uN4jB+wKwJjjPFzdkVgjDF+zhKBMcb4OUsExhjj5ywRGGOMn7NEYIwxfs4SgTHG+Ln/Dy4A8lx6hxEPAAAAAElFTkSuQmCC\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}